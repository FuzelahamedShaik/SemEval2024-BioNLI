{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b1871418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchmetrics.functional import accuracy as ACC\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchsummary import summary\n",
    "\n",
    "import time\n",
    "import nltk\n",
    "import json\n",
    "import random\n",
    "import unicodedata\n",
    "import contractions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\")\n",
    "\n",
    "#data cleaning methods\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fed1edc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "29b87143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessing(x):\n",
    "    def removeSpecialChars(x):\n",
    "        x = re.sub(r'[^\\w ]+', \" \", x)\n",
    "        x = ' '.join(x.split())\n",
    "        return x\n",
    "\n",
    "    def removeAccentedChars(x):\n",
    "        x = unicodedata.normalize('NFKD', x).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        return x\n",
    "\n",
    "    def removeStopwords(x):\n",
    "        return ' '.join([t for t in x.split() if t not in stopwords])\n",
    "\n",
    "    def removeDupsChar(x):\n",
    "        x = re.sub(\"(.)\\\\1{2,}\", \"\\\\1\", x)\n",
    "        return x\n",
    "\n",
    "    def replacing_single_char(x):\n",
    "        replacements  = {0:'zero', 1:'one', 2:'two', 3:'three', 4:'four', \n",
    "                         5:'five', 6:'six', 7:'seven', 8:'eight', 9:'nine', \n",
    "                        'n':'north','s':'south','e':'east','w':'west'}\n",
    "        def replace(t):\n",
    "            if t in replacements:\n",
    "                return replacements[t]\n",
    "            else:\n",
    "                return None\n",
    "        \n",
    "        return ' '.join(list(filter(lambda x: x is not None, [replace(t) if len(t) == 1 else t for t in x.split()])))\n",
    "\n",
    "    x = str(x).lower().replace('\\\\', '').replace('_', ' ')\n",
    "#     x = removeStopwords(x)\n",
    "    x = contractions.fix(x)  # update contractions\n",
    "    x = removeDupsChar(x)\n",
    "    x = removeAccentedChars(x)\n",
    "    x = removeSpecialChars(x)\n",
    "    x = re.sub(\"(.)\\\\1{2,}\", \"\\\\1\", x)\n",
    "    x = re.sub(r'[]!\"$%&\\'()*+,./:;=#@?[\\\\^_`{|}~-]+', \" \", x)  # punctuations, special chars\n",
    "    x = re.sub(r'\\s+', ' ', x) # Extra spaces\n",
    "#     x = replacing_single_char(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "afc1cd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 2170\n"
     ]
    }
   ],
   "source": [
    "class Load_Preprocess():\n",
    "    def __init__(self):\n",
    "        self.word2index = {}\n",
    "        self.max_len = 0\n",
    "        \n",
    "        self.Label2num = {'Entailment': 1, \"Contradiction\": 0}\n",
    "\n",
    "        self.train_df = self.Preprocess_df(pd.DataFrame.from_dict(self.load_Processed_Data(self.load_Processed_cTAKES('ctakes/Train_Statements_cTAKES_Processed.json'), 'train')), Train=True)\n",
    "        self.val_df = self.Preprocess_df(pd.DataFrame.from_dict(self.load_Processed_Data(self.load_Processed_cTAKES('ctakes/Dev_Statements_cTAKES_Processed.json'), 'dev')))\n",
    "        self.test_df = self.Preprocess_df(pd.DataFrame.from_dict(self.load_Processed_Data(self.load_Processed_cTAKES('ctakes/Test_Statements_cTAKES_Processed.json'), 'test')))\n",
    "        \n",
    "    def load_Processed_cTAKES(self, split):\n",
    "        ctakes_tokens_path = split\n",
    "        with open(ctakes_tokens_path) as json_file:\n",
    "            ctakes_tokens = json.load(json_file)\n",
    "\n",
    "        preferred_text_dict = dict()\n",
    "        for i in range(len(ctakes_tokens)):\n",
    "            cm_dict = ctakes_tokens[i]['clinical_mention']\n",
    "            temp_list = []\n",
    "            for key in cm_dict.keys():\n",
    "                try:\n",
    "                    temp_list.append(cm_dict[key][0]['preferredText'])\n",
    "                except:\n",
    "                    continue\n",
    "            preferred_text_dict[ctakes_tokens[i]['UUID'][0]] = temp_list\n",
    "        return preferred_text_dict\n",
    "\n",
    "    def load_Processed_Data(self, ctakes, split):\n",
    "        preferred_text = []\n",
    "        statement = []\n",
    "        trail1 = []\n",
    "        trail2 = []\n",
    "        section = []\n",
    "        label = []\n",
    "        \n",
    "        with open(f\"training_data/{split}\" + \".json\") as file:\n",
    "            data = json.load(file)\n",
    "            uuid_list = list(data.keys())\n",
    "\n",
    "        for id in uuid_list:\n",
    "            statement.append(data[id]['Statement'])\n",
    "            if split != 'test':\n",
    "                label.append(self.Label2num[data[id]['Label']])\n",
    "            else:\n",
    "                label.append(-1)\n",
    "            section.append(data[id]['Section_id'])\n",
    "        \n",
    "            with open(f\"training_data/CT json/{data[id]['Primary_id']}\" + \".json\") as file: \n",
    "                ct = json.load(file)\n",
    "                trail1.append(self.join_list(ct[data[id]['Section_id']]))\n",
    "                \n",
    "            if data[id]['Type'] == \"Comparison\":  \n",
    "                with open(f\"training_data/CT json/{data[id]['Secondary_id']}\" + \".json\") as file:\n",
    "                    ct = json.load(file)\n",
    "                    trail2.append(self.join_list(ct[data[id]['Section_id']]))\n",
    "            else:\n",
    "                trail2.append(\"_\")\n",
    "                \n",
    "            preferred_text.append(','.join(ctakes[id]))\n",
    "\n",
    "        return {'preferred_text':preferred_text, 'statement':statement, 'trail1':trail1, 'trail2':trail2, 'section':section, 'label':label}\n",
    "        \n",
    "    def join_list(self, sentences):\n",
    "        return \", \".join([sent.strip() for sent in sentences])\n",
    "    \n",
    "    def Preprocess_df(self, df, Train=False):\n",
    "        df['statement'] = df['statement'].apply(Preprocessing)\n",
    "        df['trail1'] = df['trail1'].apply(Preprocessing)\n",
    "        df['trail2'] = df['trail2'].apply(Preprocessing)\n",
    "\n",
    "        df[\"#Words1\"] = df[\"statement\"].apply(lambda n: len(n.split()))\n",
    "        df[\"#Words2\"] = df[\"trail1\"].apply(lambda n: len(n.split()))\n",
    "        df[\"#Words3\"] = df[\"trail2\"].apply(lambda n: len(n.split()))\n",
    "        \n",
    "        if Train:\n",
    "            self.Build_Vocabulary(df['statement'].tolist()+df['trail1'].tolist()+df['trail2'].tolist())\n",
    "        return df\n",
    "\n",
    "    def Build_Vocabulary(self, texts):\n",
    "        words = ['', 'UNK']+list(set(' '.join(texts).split()))\n",
    "        self.word2index = dict(zip(words, list(range(0, len(words)))))\n",
    "        self.max_len = self.get_max_length(texts)\n",
    "   \n",
    "    def get_max_length(self, Texts):\n",
    "        lens = [len(text.split(' ')) for text in Texts]\n",
    "        print('index', lens.index(max(lens)))\n",
    "        return max(lens)\n",
    "    \n",
    "    def Target_proportions(self, df):\n",
    "        print(df.label.value_counts())\n",
    "        sns.countplot(x=df['label']).set_title('Proportions of 0 vs 1')\n",
    "        plt.show()\n",
    "\n",
    "Data = Load_Preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "41216c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1583, 7220)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.max_len, len(Data.word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f4ad1511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preferred_text</th>\n",
       "      <th>statement</th>\n",
       "      <th>trail1</th>\n",
       "      <th>trail2</th>\n",
       "      <th>section</th>\n",
       "      <th>label</th>\n",
       "      <th>#Words1</th>\n",
       "      <th>#Words2</th>\n",
       "      <th>#Words3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Primary operation</td>\n",
       "      <td>there is a 13 2 difference between the results...</td>\n",
       "      <td>outcome measurement event free survival event ...</td>\n",
       "      <td></td>\n",
       "      <td>Results</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ejection as a Sports activity,Primary operation</td>\n",
       "      <td>patients with significantly elevated ejection ...</td>\n",
       "      <td>inclusion criteria inclusion criteria female p...</td>\n",
       "      <td>premenopausal women 55 years of age or younger...</td>\n",
       "      <td>Eligibility</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>300</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Enterocolitis,Primary operation</td>\n",
       "      <td>a significant number of the participants in th...</td>\n",
       "      <td>adverse events 1 total 20 167 11 98 cardiac fa...</td>\n",
       "      <td>adverse events 1 total 112 458 24 45 febrile n...</td>\n",
       "      <td>Adverse Events</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>142</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Primary operation</td>\n",
       "      <td>the primary trial does not report the pfs or o...</td>\n",
       "      <td>outcome measurement local control using ipsila...</td>\n",
       "      <td></td>\n",
       "      <td>Results</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Therapeutic procedure,fulvestrant</td>\n",
       "      <td>prior treatment with fulvestrant or with a pho...</td>\n",
       "      <td>inclusion criteria postmenopausal women with h...</td>\n",
       "      <td></td>\n",
       "      <td>Eligibility</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>404</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Oral cavity,Primary operation,Pharmaceutical P...</td>\n",
       "      <td>the the primary trial intervention involves on...</td>\n",
       "      <td>intervention 1 letrozole participants received...</td>\n",
       "      <td>intervention 1 sentinel lymph node biopsy not ...</td>\n",
       "      <td>Intervention</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Conjunctivitis,Primary operation</td>\n",
       "      <td>the secondary trial reported 1 single case of ...</td>\n",
       "      <td>adverse events 1 total 16 48 33 33 febrile neu...</td>\n",
       "      <td>adverse events 1 total 21 519 4 05 anaemia 1 5...</td>\n",
       "      <td>Adverse Events</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>71</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Primary operation</td>\n",
       "      <td>the secondary trial and the primary trial do n...</td>\n",
       "      <td>outcome measurement number of patients with pa...</td>\n",
       "      <td>outcome measurement disease free survival time...</td>\n",
       "      <td>Results</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>222</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Worse,Disease,Primary operation</td>\n",
       "      <td>the outcome measurement of the primary trial i...</td>\n",
       "      <td>outcome measurement progression free survival ...</td>\n",
       "      <td></td>\n",
       "      <td>Results</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Lesion,Structure of supramammillary nucleus,Pr...</td>\n",
       "      <td>all the primary trial patients had a minimum o...</td>\n",
       "      <td>outcome measurement complete response partial ...</td>\n",
       "      <td></td>\n",
       "      <td>Results</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        preferred_text  \\\n",
       "0                                    Primary operation   \n",
       "1      Ejection as a Sports activity,Primary operation   \n",
       "2                      Enterocolitis,Primary operation   \n",
       "3                                    Primary operation   \n",
       "4                    Therapeutic procedure,fulvestrant   \n",
       "..                                                 ...   \n",
       "195  Oral cavity,Primary operation,Pharmaceutical P...   \n",
       "196                   Conjunctivitis,Primary operation   \n",
       "197                                  Primary operation   \n",
       "198                    Worse,Disease,Primary operation   \n",
       "199  Lesion,Structure of supramammillary nucleus,Pr...   \n",
       "\n",
       "                                             statement  \\\n",
       "0    there is a 13 2 difference between the results...   \n",
       "1    patients with significantly elevated ejection ...   \n",
       "2    a significant number of the participants in th...   \n",
       "3    the primary trial does not report the pfs or o...   \n",
       "4    prior treatment with fulvestrant or with a pho...   \n",
       "..                                                 ...   \n",
       "195  the the primary trial intervention involves on...   \n",
       "196  the secondary trial reported 1 single case of ...   \n",
       "197  the secondary trial and the primary trial do n...   \n",
       "198  the outcome measurement of the primary trial i...   \n",
       "199  all the primary trial patients had a minimum o...   \n",
       "\n",
       "                                                trail1  \\\n",
       "0    outcome measurement event free survival event ...   \n",
       "1    inclusion criteria inclusion criteria female p...   \n",
       "2    adverse events 1 total 20 167 11 98 cardiac fa...   \n",
       "3    outcome measurement local control using ipsila...   \n",
       "4    inclusion criteria postmenopausal women with h...   \n",
       "..                                                 ...   \n",
       "195  intervention 1 letrozole participants received...   \n",
       "196  adverse events 1 total 16 48 33 33 febrile neu...   \n",
       "197  outcome measurement number of patients with pa...   \n",
       "198  outcome measurement progression free survival ...   \n",
       "199  outcome measurement complete response partial ...   \n",
       "\n",
       "                                                trail2         section  label  \\\n",
       "0                                                              Results      0   \n",
       "1    premenopausal women 55 years of age or younger...     Eligibility      0   \n",
       "2    adverse events 1 total 112 458 24 45 febrile n...  Adverse Events      0   \n",
       "3                                                              Results      1   \n",
       "4                                                          Eligibility      0   \n",
       "..                                                 ...             ...    ...   \n",
       "195  intervention 1 sentinel lymph node biopsy not ...    Intervention      0   \n",
       "196  adverse events 1 total 21 519 4 05 anaemia 1 5...  Adverse Events      1   \n",
       "197  outcome measurement disease free survival time...         Results      1   \n",
       "198                                                            Results      1   \n",
       "199                                                            Results      0   \n",
       "\n",
       "     #Words1  #Words2  #Words3  \n",
       "0         16      127        0  \n",
       "1         30      300      346  \n",
       "2         17      142      128  \n",
       "3         16       88        0  \n",
       "4         23      404        0  \n",
       "..       ...      ...      ...  \n",
       "195       21       22        8  \n",
       "196       17       71      148  \n",
       "197       17      222      118  \n",
       "198       30      184        0  \n",
       "199       21      111        0  \n",
       "\n",
       "[200 rows x 9 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "06cd47e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1700, 9), (200, 9), (5500, 9))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.train_df.shape, Data.val_df.shape, Data.test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0538f011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preferred_text</th>\n",
       "      <th>statement</th>\n",
       "      <th>trail1</th>\n",
       "      <th>trail2</th>\n",
       "      <th>section</th>\n",
       "      <th>label</th>\n",
       "      <th>#Words1</th>\n",
       "      <th>#Words2</th>\n",
       "      <th>#Words3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Primary operation</td>\n",
       "      <td>there is a 13 2 difference between the results...</td>\n",
       "      <td>outcome measurement event free survival event ...</td>\n",
       "      <td></td>\n",
       "      <td>Results</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ejection as a Sports activity,Primary operation</td>\n",
       "      <td>patients with significantly elevated ejection ...</td>\n",
       "      <td>inclusion criteria inclusion criteria female p...</td>\n",
       "      <td>premenopausal women 55 years of age or younger...</td>\n",
       "      <td>Eligibility</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>300</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Enterocolitis,Primary operation</td>\n",
       "      <td>a significant number of the participants in th...</td>\n",
       "      <td>adverse events 1 total 20 167 11 98 cardiac fa...</td>\n",
       "      <td>adverse events 1 total 112 458 24 45 febrile n...</td>\n",
       "      <td>Adverse Events</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>142</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Primary operation</td>\n",
       "      <td>the primary trial does not report the pfs or o...</td>\n",
       "      <td>outcome measurement local control using ipsila...</td>\n",
       "      <td></td>\n",
       "      <td>Results</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Therapeutic procedure,fulvestrant</td>\n",
       "      <td>prior treatment with fulvestrant or with a pho...</td>\n",
       "      <td>inclusion criteria postmenopausal women with h...</td>\n",
       "      <td></td>\n",
       "      <td>Eligibility</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>404</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    preferred_text  \\\n",
       "0                                Primary operation   \n",
       "1  Ejection as a Sports activity,Primary operation   \n",
       "2                  Enterocolitis,Primary operation   \n",
       "3                                Primary operation   \n",
       "4                Therapeutic procedure,fulvestrant   \n",
       "\n",
       "                                           statement  \\\n",
       "0  there is a 13 2 difference between the results...   \n",
       "1  patients with significantly elevated ejection ...   \n",
       "2  a significant number of the participants in th...   \n",
       "3  the primary trial does not report the pfs or o...   \n",
       "4  prior treatment with fulvestrant or with a pho...   \n",
       "\n",
       "                                              trail1  \\\n",
       "0  outcome measurement event free survival event ...   \n",
       "1  inclusion criteria inclusion criteria female p...   \n",
       "2  adverse events 1 total 20 167 11 98 cardiac fa...   \n",
       "3  outcome measurement local control using ipsila...   \n",
       "4  inclusion criteria postmenopausal women with h...   \n",
       "\n",
       "                                              trail2         section  label  \\\n",
       "0                                                            Results      0   \n",
       "1  premenopausal women 55 years of age or younger...     Eligibility      0   \n",
       "2  adverse events 1 total 112 458 24 45 febrile n...  Adverse Events      0   \n",
       "3                                                            Results      1   \n",
       "4                                                        Eligibility      0   \n",
       "\n",
       "   #Words1  #Words2  #Words3  \n",
       "0       16      127        0  \n",
       "1       30      300      346  \n",
       "2       17      142      128  \n",
       "3       16       88        0  \n",
       "4       23      404        0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "59cc1685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1583, 7220)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.max_len, len(Data.word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0629a155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0,\n",
       " 'UNK': 1,\n",
       " 't3': 2,\n",
       " 'boyd': 3,\n",
       " 'aggravated': 4,\n",
       " 'propafenone': 5,\n",
       " 'teaes': 6,\n",
       " 'dpd': 7,\n",
       " 'mouse': 8,\n",
       " 'recover': 9,\n",
       " '080': 10,\n",
       " 'accrual': 11,\n",
       " 'evista': 12,\n",
       " 'cabozantinib': 13,\n",
       " 'advanced': 14,\n",
       " 'below': 15,\n",
       " 'unborn': 16,\n",
       " 'graded': 17,\n",
       " 'volunteer': 18,\n",
       " 'assesses': 19,\n",
       " 'wellness': 20,\n",
       " 'normalization': 21,\n",
       " '60': 22,\n",
       " 'coexisting': 23,\n",
       " 'solution': 24,\n",
       " 'inherit': 25,\n",
       " 'fungal': 26,\n",
       " 'compliance': 27,\n",
       " 'motor': 28,\n",
       " 'egf': 29,\n",
       " 'feasibility': 30,\n",
       " 'progressions': 31,\n",
       " 'antigens': 32,\n",
       " '103': 33,\n",
       " 'polymorphism': 34,\n",
       " 'genders': 35,\n",
       " 'nivolumab': 36,\n",
       " 'fluocinonide': 37,\n",
       " 'psychotic': 38,\n",
       " 'n': 39,\n",
       " 'european': 40,\n",
       " '2013': 41,\n",
       " '458': 42,\n",
       " 'stenting': 43,\n",
       " 'inguinal': 44,\n",
       " 'another': 45,\n",
       " 'carboplatin': 46,\n",
       " 'coordinator': 47,\n",
       " 'concentrations': 48,\n",
       " 'next': 49,\n",
       " 'peritoneum': 50,\n",
       " '8201a': 51,\n",
       " 'rd': 52,\n",
       " 'compound': 53,\n",
       " 'necessary': 54,\n",
       " 'blockers': 55,\n",
       " 'glycemic': 56,\n",
       " 'defining': 57,\n",
       " 'mlo': 58,\n",
       " 'augmentation': 59,\n",
       " 'lignans': 60,\n",
       " 'proximally': 61,\n",
       " 'everolimus': 62,\n",
       " 'rhythm': 63,\n",
       " 'sex': 64,\n",
       " 'vial': 65,\n",
       " 'constraints': 66,\n",
       " 'histologies': 67,\n",
       " 'bifascicular': 68,\n",
       " 'dental': 69,\n",
       " 'nls': 70,\n",
       " 'requires': 71,\n",
       " 'urgent': 72,\n",
       " 'glaucoma': 73,\n",
       " 'melaena': 74,\n",
       " 'degree': 75,\n",
       " '3761': 76,\n",
       " '210': 77,\n",
       " 'most': 78,\n",
       " 'microenvironment': 79,\n",
       " 'postdose': 80,\n",
       " 'out': 81,\n",
       " 'program': 82,\n",
       " 'pyrexia1': 83,\n",
       " 'axitinib': 84,\n",
       " 'malignant': 85,\n",
       " 'skipped': 86,\n",
       " 'interval': 87,\n",
       " 'nos': 88,\n",
       " '1048': 89,\n",
       " 'seropositivity': 90,\n",
       " 'patency': 91,\n",
       " '100x': 92,\n",
       " 'minority': 93,\n",
       " 'arising': 94,\n",
       " 'lymphopenia': 95,\n",
       " 'mylan': 96,\n",
       " '002': 97,\n",
       " 'do': 98,\n",
       " 'eiae': 99,\n",
       " 'categories': 100,\n",
       " 'cytoxan': 101,\n",
       " '900mg': 102,\n",
       " '364': 103,\n",
       " 'instances': 104,\n",
       " 'ramucirumab': 105,\n",
       " 'infant': 106,\n",
       " 'anticipation': 107,\n",
       " 'bartholin': 108,\n",
       " 'withing': 109,\n",
       " 'without': 110,\n",
       " 'artificial': 111,\n",
       " 'contact': 112,\n",
       " 'certified': 113,\n",
       " 'neurosensory': 114,\n",
       " 'systole': 115,\n",
       " 'http': 116,\n",
       " '73m2': 117,\n",
       " 'personally': 118,\n",
       " 'experiecing': 119,\n",
       " 'would': 120,\n",
       " 'fever1': 121,\n",
       " 'releasing': 122,\n",
       " '133': 123,\n",
       " 'correction': 124,\n",
       " 'esophagogastroduodenoscopy': 125,\n",
       " 'terminate': 126,\n",
       " 'diathesis': 127,\n",
       " 'auc': 128,\n",
       " 'iodine': 129,\n",
       " 'entinostat': 130,\n",
       " 'drop': 131,\n",
       " 'proportions': 132,\n",
       " 'indwelling': 133,\n",
       " 'deoxyribonucleic': 134,\n",
       " 'spermicides': 135,\n",
       " 'hispanic': 136,\n",
       " 'majority': 137,\n",
       " 'nonmelanoma': 138,\n",
       " 'temsirolimus': 139,\n",
       " '733': 140,\n",
       " 'heterosexual': 141,\n",
       " 'rifabutin': 142,\n",
       " 'maintenance': 143,\n",
       " 'arrest': 144,\n",
       " 'abdominal': 145,\n",
       " 'magee': 146,\n",
       " 'written': 147,\n",
       " 'farnesyl': 148,\n",
       " 'overall': 149,\n",
       " 'world': 150,\n",
       " '114': 151,\n",
       " 'cataract1': 152,\n",
       " 'homicidal': 153,\n",
       " 'desired': 154,\n",
       " 'pathological': 155,\n",
       " 'longest': 156,\n",
       " 'hematuria': 157,\n",
       " '208': 158,\n",
       " 'subgroups': 159,\n",
       " 'after': 160,\n",
       " 'interfere': 161,\n",
       " 'cherry': 162,\n",
       " 'pharmaceuticals': 163,\n",
       " 'hematoxylin': 164,\n",
       " 'stress': 165,\n",
       " 'degrees': 166,\n",
       " 'impairs': 167,\n",
       " 'applicable': 168,\n",
       " 'providing': 169,\n",
       " 'fever': 170,\n",
       " 'nausea': 171,\n",
       " 'injectable': 172,\n",
       " 'ethnicity': 173,\n",
       " 'converted': 174,\n",
       " 'pressure': 175,\n",
       " 'preferred': 176,\n",
       " 'additionally': 177,\n",
       " 'perforatum': 178,\n",
       " '500': 179,\n",
       " 'terms': 180,\n",
       " 'disqualify': 181,\n",
       " 'holiday': 182,\n",
       " 'flutter': 183,\n",
       " 'b1': 184,\n",
       " 'extrimity': 185,\n",
       " 'discussed': 186,\n",
       " 'masses': 187,\n",
       " 'dizziness1': 188,\n",
       " 'done': 189,\n",
       " 'automatically': 190,\n",
       " 'submission': 191,\n",
       " 'uninvolved': 192,\n",
       " 'study': 193,\n",
       " 'dimensionally': 194,\n",
       " '130': 195,\n",
       " 'microcalcification': 196,\n",
       " 'myers': 197,\n",
       " 'pure': 198,\n",
       " 'hemorrhoids': 199,\n",
       " 'dermatologic': 200,\n",
       " 'embolic': 201,\n",
       " 'umrm': 202,\n",
       " 'alternate': 203,\n",
       " '600': 204,\n",
       " 'grf': 205,\n",
       " 'contained': 206,\n",
       " 'decides': 207,\n",
       " 'ability': 208,\n",
       " 'labelled': 209,\n",
       " '148': 210,\n",
       " 'radiographer': 211,\n",
       " 'vaccines': 212,\n",
       " 'hernia': 213,\n",
       " '503': 214,\n",
       " 'temperature': 215,\n",
       " 'primary': 216,\n",
       " 'phosphate': 217,\n",
       " 'conducting': 218,\n",
       " 'palpation': 219,\n",
       " 'ca27': 220,\n",
       " 'explored': 221,\n",
       " 'resolved': 222,\n",
       " 'exercises': 223,\n",
       " 'breslow': 224,\n",
       " 'successfully': 225,\n",
       " 'gov': 226,\n",
       " '1635': 227,\n",
       " 'creterion': 228,\n",
       " 'angioedema': 229,\n",
       " 'pten': 230,\n",
       " 'diastolic': 231,\n",
       " 'ffdm': 232,\n",
       " 'incapable': 233,\n",
       " 'instead': 234,\n",
       " 'collapsed': 235,\n",
       " 'bipolar': 236,\n",
       " 'prescribing': 237,\n",
       " 'calculate': 238,\n",
       " 'toremifene': 239,\n",
       " 'male': 240,\n",
       " 'initiate': 241,\n",
       " 'align': 242,\n",
       " 'close': 243,\n",
       " 'addendum': 244,\n",
       " 'sterilizing': 245,\n",
       " 'compounds': 246,\n",
       " 'lymphocele': 247,\n",
       " 'captured': 248,\n",
       " 'being': 249,\n",
       " 'her': 250,\n",
       " 'medicinal': 251,\n",
       " 'modulators': 252,\n",
       " 'familial': 253,\n",
       " 'namely': 254,\n",
       " 'cognitive': 255,\n",
       " 'dp': 256,\n",
       " 'portion': 257,\n",
       " 'bmi': 258,\n",
       " 'cephalea': 259,\n",
       " 'begin': 260,\n",
       " '6th': 261,\n",
       " 'pac': 262,\n",
       " 'ascites': 263,\n",
       " 'birth': 264,\n",
       " 'to': 265,\n",
       " '437': 266,\n",
       " 'facilitator': 267,\n",
       " 'into': 268,\n",
       " 'consultant': 269,\n",
       " 'fludarabine': 270,\n",
       " 'prs': 271,\n",
       " 'crossover': 272,\n",
       " 'tautness': 273,\n",
       " 'write': 274,\n",
       " 'beverages': 275,\n",
       " 'cr': 276,\n",
       " 'neoplasm': 277,\n",
       " 'ib': 278,\n",
       " 'coagulant': 279,\n",
       " 'adipokines': 280,\n",
       " 'refused': 281,\n",
       " 'makes': 282,\n",
       " 'haitian': 283,\n",
       " 'heterogeneously': 284,\n",
       " 'benefit': 285,\n",
       " 'back1': 286,\n",
       " '10e': 287,\n",
       " 'aspects': 288,\n",
       " 'fetal': 289,\n",
       " 'thorax1': 290,\n",
       " 'abrupt': 291,\n",
       " 'q3weeks': 292,\n",
       " 'poisoning': 293,\n",
       " 'excess': 294,\n",
       " 'omolateral': 295,\n",
       " 'prevention': 296,\n",
       " 'pa': 297,\n",
       " 'exhibiting': 298,\n",
       " 'erythema': 299,\n",
       " 'tivantinib': 300,\n",
       " 'vg': 301,\n",
       " 'preserve': 302,\n",
       " 'implants': 303,\n",
       " 'imagio': 304,\n",
       " 'possibly': 305,\n",
       " 'designed': 306,\n",
       " 'under': 307,\n",
       " 'sta': 308,\n",
       " 'scores': 309,\n",
       " 'scheme': 310,\n",
       " 'share': 311,\n",
       " 'flap': 312,\n",
       " 'enhancement': 313,\n",
       " 'knpcb': 314,\n",
       " 'isolation': 315,\n",
       " 'intervertebral': 316,\n",
       " 'plasma': 317,\n",
       " 'examined': 318,\n",
       " 'inflammation': 319,\n",
       " 'biliary': 320,\n",
       " '530': 321,\n",
       " '013736': 322,\n",
       " 'cohosh': 323,\n",
       " 'matching': 324,\n",
       " 'proteins': 325,\n",
       " 'hematologic': 326,\n",
       " 'bp': 327,\n",
       " 'participating': 328,\n",
       " 'embedded': 329,\n",
       " 'referring': 330,\n",
       " 'reliably': 331,\n",
       " 'calculus': 332,\n",
       " 'menorrhagia': 333,\n",
       " 'guideline': 334,\n",
       " 'pn0': 335,\n",
       " 'postoperatively': 336,\n",
       " 'transvaginal': 337,\n",
       " '369': 338,\n",
       " 'ulceration': 339,\n",
       " 'follow': 340,\n",
       " 'these': 341,\n",
       " 'demonstration': 342,\n",
       " 'txn1m0': 343,\n",
       " 'pathologist': 344,\n",
       " 'ecg': 345,\n",
       " 'obstruction': 346,\n",
       " 'nonhematological': 347,\n",
       " 'analogue': 348,\n",
       " 'directed': 349,\n",
       " 'prophylactic': 350,\n",
       " '480': 351,\n",
       " 'lde225': 352,\n",
       " 'reductions': 353,\n",
       " 'cellular': 354,\n",
       " 'colon': 355,\n",
       " '64': 356,\n",
       " 'analyzed': 357,\n",
       " 'salt': 358,\n",
       " 'attachment': 359,\n",
       " 'aleve': 360,\n",
       " 'mad': 361,\n",
       " 'discuss': 362,\n",
       " '146': 363,\n",
       " 'therefore': 364,\n",
       " 'type': 365,\n",
       " 'obscure': 366,\n",
       " 'hiistologically': 367,\n",
       " 'facilitated': 368,\n",
       " 'cardiomyopathy': 369,\n",
       " 'mimic': 370,\n",
       " 'bikes': 371,\n",
       " 'regimen': 372,\n",
       " 'specifically': 373,\n",
       " 'material': 374,\n",
       " 'websites': 375,\n",
       " 'notable': 376,\n",
       " 'calorie': 377,\n",
       " 'zirconium': 378,\n",
       " 'exams': 379,\n",
       " 'papular': 380,\n",
       " 'spermatogenesis': 381,\n",
       " 'incidents': 382,\n",
       " 'john': 383,\n",
       " 'observations': 384,\n",
       " '24hrs': 385,\n",
       " 'body': 386,\n",
       " 'banked': 387,\n",
       " 'tipifarnib': 388,\n",
       " 'communicate': 389,\n",
       " 'pr': 390,\n",
       " 'pmrt': 391,\n",
       " 'clip': 392,\n",
       " 'unspecified': 393,\n",
       " 'cell': 394,\n",
       " 'used': 395,\n",
       " 'institutional': 396,\n",
       " 'node': 397,\n",
       " 'unavailability': 398,\n",
       " 'village': 399,\n",
       " '3rd': 400,\n",
       " 'darbepoetin': 401,\n",
       " 'extending': 402,\n",
       " 'covered': 403,\n",
       " 'streptococcus': 404,\n",
       " 'dl': 405,\n",
       " 'taxanes': 406,\n",
       " 'contrast': 407,\n",
       " 'centers': 408,\n",
       " 'contain': 409,\n",
       " 'shock': 410,\n",
       " 'discussion': 411,\n",
       " 'got': 412,\n",
       " 'calibrated': 413,\n",
       " 'strontium': 414,\n",
       " 'secure': 415,\n",
       " 'epileptic': 416,\n",
       " 'suppository': 417,\n",
       " 'bi': 418,\n",
       " 'ulcerative': 419,\n",
       " 'impairments': 420,\n",
       " 'mi': 421,\n",
       " 'authorization': 422,\n",
       " 'goal': 423,\n",
       " 'cis': 424,\n",
       " 'demonstrated': 425,\n",
       " 'isolated': 426,\n",
       " 'elicit': 427,\n",
       " 'chi': 428,\n",
       " 'objective': 429,\n",
       " 'recorded': 430,\n",
       " 'nk': 431,\n",
       " 'fractionation': 432,\n",
       " 'mammalian': 433,\n",
       " 'virus': 434,\n",
       " 'real': 435,\n",
       " 'borderline': 436,\n",
       " '1650': 437,\n",
       " 'protectant': 438,\n",
       " 'destruction': 439,\n",
       " 'general': 440,\n",
       " 'usa': 441,\n",
       " 'cdc': 442,\n",
       " 'ethnic': 443,\n",
       " 'gamma': 444,\n",
       " 'sudden': 445,\n",
       " 'randomized': 446,\n",
       " 'undertaking': 447,\n",
       " 'requirement': 448,\n",
       " 'inoculations': 449,\n",
       " 'anilinoquinazoline': 450,\n",
       " 'transformation': 451,\n",
       " 'assessed': 452,\n",
       " 'overactive': 453,\n",
       " '368': 454,\n",
       " 'recovering': 455,\n",
       " 'cluster': 456,\n",
       " 'score': 457,\n",
       " 'haemorrhoidal': 458,\n",
       " 'shi': 459,\n",
       " 'arteriospasm': 460,\n",
       " 'elects': 461,\n",
       " '06': 462,\n",
       " 'monitoring': 463,\n",
       " 'malate': 464,\n",
       " 'subfamily': 465,\n",
       " 'rad001': 466,\n",
       " 'reasonable': 467,\n",
       " 'chemoprevention': 468,\n",
       " 'pericarditis1': 469,\n",
       " 'indinavir': 470,\n",
       " 'state': 471,\n",
       " 'equals': 472,\n",
       " '27': 473,\n",
       " 'fluoropyrimidine': 474,\n",
       " 'agent': 475,\n",
       " 'mitogen': 476,\n",
       " 'leukocytosis': 477,\n",
       " 'achieving': 478,\n",
       " 'hi': 479,\n",
       " 'angiographically': 480,\n",
       " 'regimens': 481,\n",
       " 'filled': 482,\n",
       " 'remains': 483,\n",
       " 'magnesium': 484,\n",
       " 'n1b': 485,\n",
       " 'phenothiazines': 486,\n",
       " 'digoxin': 487,\n",
       " 'hypercoagulability': 488,\n",
       " '2014': 489,\n",
       " '410': 490,\n",
       " 'site': 491,\n",
       " 'such': 492,\n",
       " 'measurable': 493,\n",
       " 'nanoparticle': 494,\n",
       " 'taxol': 495,\n",
       " 'occured': 496,\n",
       " '488': 497,\n",
       " '36': 498,\n",
       " 'office': 499,\n",
       " 'meaningful': 500,\n",
       " 'antibiotic': 501,\n",
       " 'extracapsular': 502,\n",
       " 'intradermally': 503,\n",
       " '60ml': 504,\n",
       " '352': 505,\n",
       " 'gu': 506,\n",
       " 'ensure': 507,\n",
       " 'abnormally': 508,\n",
       " 'sevoflurane': 509,\n",
       " 'cover': 510,\n",
       " 'future': 511,\n",
       " 'ingested': 512,\n",
       " 'biodesign': 513,\n",
       " 'too': 514,\n",
       " 'route': 515,\n",
       " 'exceed': 516,\n",
       " 'gastroduodenal': 517,\n",
       " 'enlargement': 518,\n",
       " 'germline': 519,\n",
       " '25': 520,\n",
       " 'prescribed': 521,\n",
       " 'march': 522,\n",
       " 'n1c': 523,\n",
       " 'qpcr': 524,\n",
       " 'vas': 525,\n",
       " 'sjogren': 526,\n",
       " 'distinct': 527,\n",
       " 'mannitol': 528,\n",
       " 'regions': 529,\n",
       " 'erk': 530,\n",
       " 'pancytopenia1': 531,\n",
       " 'stabilize': 532,\n",
       " 'hospitalisation': 533,\n",
       " 'inr': 534,\n",
       " 'oxaloacetic': 535,\n",
       " 'elizabeth': 536,\n",
       " 'altered': 537,\n",
       " '206': 538,\n",
       " 'sensitization': 539,\n",
       " 'substrate': 540,\n",
       " 'methylprednisolone': 541,\n",
       " 'insipidus': 542,\n",
       " 'linear': 543,\n",
       " 'azd4547': 544,\n",
       " 'attribution': 545,\n",
       " 'supplementary': 546,\n",
       " 'cat': 547,\n",
       " 'zofran': 548,\n",
       " 'chinese': 549,\n",
       " 'possible': 550,\n",
       " 'massage': 551,\n",
       " 'lidocaine': 552,\n",
       " 'ipatasertib': 553,\n",
       " 'designated': 554,\n",
       " 'constructed': 555,\n",
       " 'antiemetics': 556,\n",
       " 'who': 557,\n",
       " 'hypercalcemia1': 558,\n",
       " 'block': 559,\n",
       " 'occasional': 560,\n",
       " 'organs': 561,\n",
       " 'pharmacogenetics': 562,\n",
       " 'psychosis': 563,\n",
       " 'hydrastis': 564,\n",
       " 'mellitus': 565,\n",
       " 'anytime': 566,\n",
       " 'variety': 567,\n",
       " 'niraparib': 568,\n",
       " 'dozen': 569,\n",
       " 'stop': 570,\n",
       " 'granulocytosis': 571,\n",
       " 'reasons': 572,\n",
       " 'inventory': 573,\n",
       " 'rpfna': 574,\n",
       " 'format': 575,\n",
       " 'distal': 576,\n",
       " 'constipation': 577,\n",
       " 'oxide': 578,\n",
       " 'bronchospastic': 579,\n",
       " 'gauze': 580,\n",
       " 'trunck': 581,\n",
       " 'small': 582,\n",
       " 'cish': 583,\n",
       " 'ablation': 584,\n",
       " 'brugada': 585,\n",
       " 'record': 586,\n",
       " 'stained': 587,\n",
       " 'determined': 588,\n",
       " 'aerobic': 589,\n",
       " 'raloxifene': 590,\n",
       " 'recommends': 591,\n",
       " 'forced': 592,\n",
       " 'solitary': 593,\n",
       " 'slide': 594,\n",
       " 'signal': 595,\n",
       " 'neoadjuvantly': 596,\n",
       " 'supervised': 597,\n",
       " 're': 598,\n",
       " 'patch': 599,\n",
       " 'patinets': 600,\n",
       " 'adenoma': 601,\n",
       " 'ingest': 602,\n",
       " 'taper': 603,\n",
       " 'breakfast': 604,\n",
       " 'asthma': 605,\n",
       " 'liberty': 606,\n",
       " 'plain': 607,\n",
       " 'diuretic': 608,\n",
       " 'transaminase': 609,\n",
       " 'progression': 610,\n",
       " 'tolerated': 611,\n",
       " 'fleming': 612,\n",
       " 'morning': 613,\n",
       " 'id': 614,\n",
       " 'antiretroviral': 615,\n",
       " 'complicated': 616,\n",
       " 'cohort1': 617,\n",
       " 'serial': 618,\n",
       " 'add': 619,\n",
       " 'endothelial': 620,\n",
       " 'monohydrate': 621,\n",
       " 'vasectomised': 622,\n",
       " 'ginseng': 623,\n",
       " 'ffpe': 624,\n",
       " 'held': 625,\n",
       " 'neu': 626,\n",
       " 'bor': 627,\n",
       " '388': 628,\n",
       " 'deteriorating': 629,\n",
       " 'movement': 630,\n",
       " 'veins': 631,\n",
       " 'develops': 632,\n",
       " 'workflow': 633,\n",
       " 'variability': 634,\n",
       " 'vbd': 635,\n",
       " 'insomnia': 636,\n",
       " 'eligilbe': 637,\n",
       " 'insufficiency': 638,\n",
       " 'branch': 639,\n",
       " 'carcinomatous': 640,\n",
       " 'experiencing': 641,\n",
       " '1cm': 642,\n",
       " 'superficial': 643,\n",
       " 'his': 644,\n",
       " 'themselves': 645,\n",
       " 'overlap': 646,\n",
       " 'responding': 647,\n",
       " 'pericardial': 648,\n",
       " 'calcitriol': 649,\n",
       " 'children': 650,\n",
       " 'anaprox': 651,\n",
       " 'discovered': 652,\n",
       " '75mm': 653,\n",
       " 'fourth': 654,\n",
       " 'pilocarpine': 655,\n",
       " 'resumed': 656,\n",
       " 'radical': 657,\n",
       " 'pik3ca': 658,\n",
       " 'positron': 659,\n",
       " 'deep': 660,\n",
       " 'tissue': 661,\n",
       " 'aimrt': 662,\n",
       " 'plus': 663,\n",
       " 'armpit': 664,\n",
       " 'aids': 665,\n",
       " '124': 666,\n",
       " 'resectable': 667,\n",
       " 'androgens': 668,\n",
       " 'withdraw': 669,\n",
       " 'focus': 670,\n",
       " '1401o': 671,\n",
       " 'formestane': 672,\n",
       " 'races': 673,\n",
       " 'haemorrhage': 674,\n",
       " 'direct': 675,\n",
       " '3400': 676,\n",
       " 'beams': 677,\n",
       " 'esophageal': 678,\n",
       " 'galt': 679,\n",
       " 'surgical': 680,\n",
       " 'prohibitive': 681,\n",
       " 'turn': 682,\n",
       " '304': 683,\n",
       " '15': 684,\n",
       " 'juices': 685,\n",
       " 'fibromyalgia': 686,\n",
       " 'illness': 687,\n",
       " 'alobresib': 688,\n",
       " '373': 689,\n",
       " 'damage': 690,\n",
       " 'slow': 691,\n",
       " '1285': 692,\n",
       " 'ntl': 693,\n",
       " 'suicides': 694,\n",
       " 'necessarily': 695,\n",
       " 'laws': 696,\n",
       " '800mg': 697,\n",
       " 'society': 698,\n",
       " 'exclude': 699,\n",
       " 'usual': 700,\n",
       " 'relafin': 701,\n",
       " 'blindness': 702,\n",
       " 'return': 703,\n",
       " 'milliliter': 704,\n",
       " 'troleandomycin': 705,\n",
       " 'pecs': 706,\n",
       " 'survivors': 707,\n",
       " '221': 708,\n",
       " 'reliable': 709,\n",
       " 'losartan': 710,\n",
       " 'drastically': 711,\n",
       " '125': 712,\n",
       " 'duty': 713,\n",
       " '155': 714,\n",
       " 'investigation': 715,\n",
       " 'relationships': 716,\n",
       " 'restart': 717,\n",
       " 'based': 718,\n",
       " 'lab': 719,\n",
       " 'conservative': 720,\n",
       " 'axilla': 721,\n",
       " 'cryptogenic': 722,\n",
       " 'intradural': 723,\n",
       " 'confusional': 724,\n",
       " 'parent': 725,\n",
       " 'trifolium': 726,\n",
       " 'naive': 727,\n",
       " 'lymph': 728,\n",
       " 'coumadin': 729,\n",
       " 'coronary': 730,\n",
       " 'lobar': 731,\n",
       " 'off': 732,\n",
       " 'more': 733,\n",
       " 'meso': 734,\n",
       " 'visits': 735,\n",
       " 'take': 736,\n",
       " '300': 737,\n",
       " 'moab': 738,\n",
       " 'always': 739,\n",
       " 'triglycerides': 740,\n",
       " 'triamcinolone': 741,\n",
       " 'stability': 742,\n",
       " 'minutes': 743,\n",
       " 'huge': 744,\n",
       " 'reduces': 745,\n",
       " 'weekly': 746,\n",
       " 'muscular': 747,\n",
       " 'entirely': 748,\n",
       " 'saturation': 749,\n",
       " '680': 750,\n",
       " 'undergoing': 751,\n",
       " 'clinic': 752,\n",
       " 'flash': 753,\n",
       " 'hydrophor': 754,\n",
       " 'model': 755,\n",
       " 'dyspnea': 756,\n",
       " 'symptoms': 757,\n",
       " 'exclusively': 758,\n",
       " 'neutrophilic': 759,\n",
       " 'pn1a': 760,\n",
       " 'provision': 761,\n",
       " 'gadolinium': 762,\n",
       " 'statistical': 763,\n",
       " 'appearance': 764,\n",
       " '90mmhg': 765,\n",
       " 'motility': 766,\n",
       " 'tnbc': 767,\n",
       " 'substitute': 768,\n",
       " 'loading': 769,\n",
       " '288': 770,\n",
       " 'national': 771,\n",
       " 'involved': 772,\n",
       " 'older': 773,\n",
       " 'calcitonin': 774,\n",
       " 'usually': 775,\n",
       " 'changed': 776,\n",
       " 'tachycardia1': 777,\n",
       " 'aorta': 778,\n",
       " 'simultaneously': 779,\n",
       " 'peptides': 780,\n",
       " 'obligatory': 781,\n",
       " 'angina': 782,\n",
       " 'ctla': 783,\n",
       " 'status': 784,\n",
       " 'that': 785,\n",
       " 'unifocal': 786,\n",
       " 'but': 787,\n",
       " 'asparagine': 788,\n",
       " 'twice': 789,\n",
       " 'monday': 790,\n",
       " 'stated': 791,\n",
       " '2capecitabine': 792,\n",
       " 'insertion': 793,\n",
       " 'cobimetinib': 794,\n",
       " 'allergens': 795,\n",
       " 'limited': 796,\n",
       " 'separated': 797,\n",
       " 'terminal': 798,\n",
       " 'existing': 799,\n",
       " 'fetuses': 800,\n",
       " 'reading': 801,\n",
       " 'motivational': 802,\n",
       " 'pbi': 803,\n",
       " 'rapamycin': 804,\n",
       " 'intelligent': 805,\n",
       " 'neurosurgery': 806,\n",
       " 'portability': 807,\n",
       " 'critical': 808,\n",
       " '750mg': 809,\n",
       " 'nodal': 810,\n",
       " 'part': 811,\n",
       " 'intestinal': 812,\n",
       " 'polymorphs': 813,\n",
       " 'higher': 814,\n",
       " 'kidneys': 815,\n",
       " 'paula': 816,\n",
       " 'urticaria': 817,\n",
       " 'terminology': 818,\n",
       " 'abemaciclib': 819,\n",
       " 'micrometastasis': 820,\n",
       " 'local': 821,\n",
       " '486': 822,\n",
       " 'ofs': 823,\n",
       " 'b12': 824,\n",
       " '23': 825,\n",
       " 'medical': 826,\n",
       " 'longer': 827,\n",
       " 'fatigue': 828,\n",
       " '3x': 829,\n",
       " 'spgt': 830,\n",
       " 'just': 831,\n",
       " 'declined': 832,\n",
       " '4d': 833,\n",
       " 'leukapheresis': 834,\n",
       " 'supplying': 835,\n",
       " 'bazett': 836,\n",
       " 'sequencing': 837,\n",
       " 'pneumococcal': 838,\n",
       " '44': 839,\n",
       " 'fixed': 840,\n",
       " 'component': 841,\n",
       " 'professional': 842,\n",
       " 'for': 843,\n",
       " 'polysomy': 844,\n",
       " 'ccnd1': 845,\n",
       " 'previously': 846,\n",
       " 'palpable': 847,\n",
       " 'cdk': 848,\n",
       " 'sae': 849,\n",
       " 'extra': 850,\n",
       " 'foot': 851,\n",
       " 'intense': 852,\n",
       " 'please': 853,\n",
       " 'create': 854,\n",
       " 'might': 855,\n",
       " 'beat': 856,\n",
       " '50kg': 857,\n",
       " 'pelvis': 858,\n",
       " 'eortc': 859,\n",
       " 'understanding': 860,\n",
       " 'repeat': 861,\n",
       " 'survivorship': 862,\n",
       " 'suggestive': 863,\n",
       " 'spanish': 864,\n",
       " 'account': 865,\n",
       " 'vomiting': 866,\n",
       " 'cn2b': 867,\n",
       " '5': 868,\n",
       " 'knp': 869,\n",
       " 'allowed': 870,\n",
       " 'other1': 871,\n",
       " 'decision': 872,\n",
       " 'girth': 873,\n",
       " 'worsened': 874,\n",
       " 'grouped': 875,\n",
       " 'preventing': 876,\n",
       " 'scanner': 877,\n",
       " 'week': 878,\n",
       " 'gastritis': 879,\n",
       " 'ferromagnetic': 880,\n",
       " 'antiviral': 881,\n",
       " 'od': 882,\n",
       " 'men': 883,\n",
       " 'acth': 884,\n",
       " 'happening': 885,\n",
       " 'method': 886,\n",
       " 'cdx': 887,\n",
       " 'prejudice': 888,\n",
       " 'uniform': 889,\n",
       " 'medroxyprogesterone': 890,\n",
       " 'areola': 891,\n",
       " 'pn1c': 892,\n",
       " 'proceeding': 893,\n",
       " 'eligible': 894,\n",
       " 'legally': 895,\n",
       " 'censoring': 896,\n",
       " 'analog': 897,\n",
       " 'irregularities': 898,\n",
       " '3cellulitis': 899,\n",
       " 'pericarditis': 900,\n",
       " 'nac': 901,\n",
       " 'disease': 902,\n",
       " 'fistulae': 903,\n",
       " 'ast': 904,\n",
       " 'micronized': 905,\n",
       " 'chemopreventive': 906,\n",
       " 'ineligible': 907,\n",
       " 'talazoparib': 908,\n",
       " 'supplement': 909,\n",
       " 'palliative': 910,\n",
       " '484': 911,\n",
       " 'geographic': 912,\n",
       " 'metabolic': 913,\n",
       " 'feet': 914,\n",
       " 'oxaloacetate': 915,\n",
       " 'decrease': 916,\n",
       " 'compromises': 917,\n",
       " 'censor': 918,\n",
       " 'residing': 919,\n",
       " '8th': 920,\n",
       " 'suvmean': 921,\n",
       " '12mg': 922,\n",
       " 'antiangiogenics': 923,\n",
       " 'cdp': 924,\n",
       " 'helps': 925,\n",
       " 'water': 926,\n",
       " '70mm': 927,\n",
       " 'clot': 928,\n",
       " 'septic': 929,\n",
       " 'groups': 930,\n",
       " 'successful': 931,\n",
       " 'neutropenia4': 932,\n",
       " 'ileus': 933,\n",
       " 'than': 934,\n",
       " '7': 935,\n",
       " '198': 936,\n",
       " 'hg': 937,\n",
       " 'wort': 938,\n",
       " 'count': 939,\n",
       " 'l2': 940,\n",
       " 'bigeminy': 941,\n",
       " 'consenting': 942,\n",
       " 'regiments': 943,\n",
       " 'translational': 944,\n",
       " 'caps': 945,\n",
       " 'ca15': 946,\n",
       " 'tdp': 947,\n",
       " 'ranges': 948,\n",
       " '53': 949,\n",
       " 'inclusion': 950,\n",
       " 'alive': 951,\n",
       " '137': 952,\n",
       " 'corticosteroids': 953,\n",
       " 'dexamethasone': 954,\n",
       " 'survive': 955,\n",
       " 'approved': 956,\n",
       " 'ages': 957,\n",
       " 'incurable': 958,\n",
       " 'increase': 959,\n",
       " '50': 960,\n",
       " 'fluid': 961,\n",
       " 'push': 962,\n",
       " 'neuvax': 963,\n",
       " 'neutropenia11': 964,\n",
       " 'functioning': 965,\n",
       " 'biotherapy': 966,\n",
       " 'pills': 967,\n",
       " 'major': 968,\n",
       " 'ethnically': 969,\n",
       " 'increasing': 970,\n",
       " 'red': 971,\n",
       " 'disadvantages': 972,\n",
       " 'polyethylene': 973,\n",
       " 'proximity': 974,\n",
       " 'whatsoever': 975,\n",
       " 'aswell': 976,\n",
       " 'nonmeasurable': 977,\n",
       " 'imputed': 978,\n",
       " 'tracer': 979,\n",
       " 'sheets': 980,\n",
       " 'page': 981,\n",
       " 'minimum': 982,\n",
       " 'relationship': 983,\n",
       " 'stepwedge': 984,\n",
       " 'average': 985,\n",
       " '93': 986,\n",
       " 'progestin': 987,\n",
       " 'miller': 988,\n",
       " 'ki67': 989,\n",
       " 'amiodarone': 990,\n",
       " 'emission': 991,\n",
       " 'diarrheal': 992,\n",
       " 'young': 993,\n",
       " 'cdk4': 994,\n",
       " 'cystitis': 995,\n",
       " 'calendar': 996,\n",
       " 'significance': 997,\n",
       " 'lcl161': 998,\n",
       " 'survey': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d7cf621c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2193"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin([len(text.split()) for text in Data.train_df['statement'].tolist()+Data.train_df['trail1'].tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e4d8b525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'intervention 1 maestro baseline'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [text for text in Data.train_df['statement'].tolist()+Data.train_df['trail1'].tolist()+Data.train_df['trail2'].tolist()]\n",
    "texts[2193]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "04565b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Data.train_df[\"#Words1\"].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bf416404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 4, 0)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(Data.train_df[\"#Words1\"].to_numpy()), min(Data.train_df[\"#Words2\"].to_numpy()), min(Data.train_df[\"#Words3\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "65fcbbd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 1583, 1405)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(Data.train_df[\"#Words1\"].to_numpy()), max(Data.train_df[\"#Words2\"].to_numpy()), max(Data.train_df[\"#Words3\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "348fee18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    100\n",
      "1    100\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHFCAYAAAAUpjivAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAApF0lEQVR4nO3dfVTUdd7/8dcIMoAiK4ozoKhYtNriXdKy2iqaiWtpeblZqZdpth1bLJd0U7lcE2yDpNY4xmqre1LTTK/aS9drW1s5lnSjniVX86Y022XVXSHKEFARBL+/P/wxV9PgHQzM8PH5OGfOcT7zmS/vrx2X535nBmyWZVkCAAAwVCtfDwAAANCUiB0AAGA0YgcAABiN2AEAAEYjdgAAgNGIHQAAYDRiBwAAGI3YAQAARiN2AACA0YgdwM+sXr1aNpvNdQsMDFSXLl30yCOP6N///revx2uwTz/9VOnp6frnP//p8djUqVPVvXv3Zp/J2/bu3aukpCSFh4fLZrMpJyfnivs3bNigfv36KTg4WNHR0UpNTdWZM2eaZ9ir+NWvfqXRo0erc+fOstlsmjp1qq9HAhqM2AH81KpVq7Rr1y7l5eXpscce0xtvvKHBgwfr7Nmzvh6tQT799FNlZGTUGzsLFizQpk2bmn8oL5s2bZqKioq0YcMG7dq1Sw899NBl977++uuaMGGCbr/9dm3dulULFy7U6tWrNW7cuGac+PJeeuklnTp1Svfee6+CgoJ8PQ7QKIG+HgBA/eLj45WQkCBJGjZsmGpra/Xss89q8+bNmjRpUr3POXfunEJDQ5tzzKu6cOGCbDbbFffcdNNNzTRN0zp48KAee+wxjRo16or7amtr9fTTTys5OVkrV66UdOm/cVhYmCZNmqStW7de9RhNraKiQq1aXfr/w2vXrvXpLEBjcWUHaCF+9KMfSZKOHTsm6dJLP23bttWBAweUnJyssLAwDR8+XJL0zTffKCUlRZ07d1ZQUJB69Oih+fPnq6qqyu2YNptNTzzxhH73u9/plltukd1u16233qoNGzZ4fP2DBw/qvvvuU/v27RUcHKx+/fppzZo1bnt27Nghm82mtWvXavbs2ercubPsdrt+//vfa/z48ZIufVOve4lu9erVrnP57stY58+fV1pammJjYxUUFKTOnTtrxowZOn36tNu+7t27a/To0XrnnXd02223KSQkRD179tSrr77qtu/cuXP65S9/qdjYWAUHBysiIkIJCQl64403rvp3f7Vzr3vpsaamRsuXL3ed3+Xs3r1bRUVFeuSRR9zWx48fr7Zt217xKtdXX32loKAgLViwwOOxw4cPy2azaenSpY0+57rQAUzAlR2ghfjiiy8kSZGRka616upq3XvvvZo+fbrmzZunmpoanT9/XsOGDdPf//53ZWRkqE+fPvrggw+UlZWlffv26e2333Y77pYtW/Tee+9p0aJFatOmjZYtW6YJEyYoMDBQ999/vyTpyJEjGjRokDp16qSlS5eqQ4cOWrdunaZOnaovv/xSc+bMcTtmWlqaBg4cqFdeeUWtWrVSQkKCSktL9V//9V/67W9/q9tuu03S5a/oWJalsWPHavv27UpLS9PgwYO1f/9+LVy4ULt27dKuXbtkt9td+z/55BPNnj1b8+bNk8Ph0O9//3s9+uijuvnmmzVkyBBJ0qxZs7R27Vr9+te/Vv/+/XX27FkdPHhQp06duuLf+7Wc+z333KNdu3Zp4MCBuv/++zV79uwrHvPgwYOSpD59+ritt27dWj179nQ9Xp/IyEiNHj1aa9asUUZGhluUrFq1SkFBQa4rfw09Z8A4FgC/smrVKkuStXv3buvChQtWRUWF9ac//cmKjIy0wsLCrOLiYsuyLGvKlCmWJOvVV191e/4rr7xiSbL++7//22198eLFliRr27ZtrjVJVkhIiOuYlmVZNTU1Vs+ePa2bb77ZtfbQQw9ZdrvdOn78uNsxR40aZYWGhlqnT5+2LMuy3nvvPUuSNWTIEI/zevPNNy1J1nvvvefx2JQpU6xu3bq57r/zzjuWJCs7O9tt38aNGy1J1ooVK1xr3bp1s4KDg61jx4651iorK62IiAhr+vTprrX4+Hhr7NixHl/7aq713C3r0t/njBkzrnrM5557zpJkFRUVeTyWnJxs3XLLLVd8/pYtWzz+W9bU1FjR0dHWT3/6U9daQ8/5u9q0aWNNmTKl0ccBfIXrlICf+tGPfqTWrVsrLCxMo0ePltPp1NatW+VwONz2/fSnP3W7/+6776pNmzauqzJ16j5Ns337drf14cOHux0zICBADz74oL744gv961//ch1z+PDhiomJ8TjmuXPntGvXrivOdL3effddt5nrjB8/Xm3atPE4h379+qlr166u+8HBwbrllltcL/lJ0g9/+ENt3bpV8+bN044dO1RZWXnNs1zPuV+Py73UdbX3OI0aNUpOp1OrVq1yrf3lL3/RyZMnNW3aNNdaQ88ZMA2xA/ip1157TQUFBdq7d69Onjyp/fv364477nDbExoaqnbt2rmtnTp1Sk6n0+MbZqdOnRQYGOjxEobT6fT42nVrdXtPnTqlqKgoj33R0dFu++rUt/d6nDp1SoGBgW4v2UmXIsDpdHp8vQ4dOngcw263u31zX7p0qebOnavNmzdr2LBhioiI0NixY3X06NGrznI9534t6uat77nffPONIiIirvj8wMBATZ48WZs2bXK9h2n16tWKiorSyJEjXfsaes6AaYgdwE/16tVLCQkJ6tev32Xjob4rAB06dNCXX34py7Lc1ktKSlRTU6OOHTu6rRcXF3sco26t7ptyhw4dVFRU5LHv5MmTkuRxzKtdmbiaDh06qKamRl999ZXbumVZKi4u9vh616JNmzbKyMjQ4cOHVVxcrOXLl2v37t0aM2bMVWe5nnO/Fr1795YkHThwwG29pqZGhw8fVnx8/FWP8cgjj+j8+fPasGGDSktLtWXLFj388MMKCAhw7WnoOQOmIXYAwwwfPlxnzpzR5s2b3dZfe+011+Pftn37dn355Zeu+7W1tdq4caNuuukmdenSxfWcd9991/UN/tvHDA0NdX1S7Erq3lB8LS+l1M24bt06t/U//OEPOnv2rMc5XC+Hw6GpU6dqwoQJOnLkiM6dO3fFWRp77t+VmJioqKgo16fR6rz11ls6c+bMNf2snV69eikxMVGrVq3S+vXrVVVV5fHprm+7nnMGTMOnsQDDPPzww/rtb3+rKVOm6J///Kd69+6tDz/8UJmZmbr77rt11113ue3v2LGj7rzzTi1YsMD1aazDhw+7ffx84cKF+tOf/qRhw4bpmWeeUUREhF5//XW9/fbbys7OVnh4+FXnqrtasWLFCoWFhSk4OFixsbH1vgQ1YsQIjRw5UnPnzlV5ebnuuOMO16ex+vfvr8mTJ1/330tiYqJGjx6tPn36qH379vrss8+0du1aDRw48Io/m8gb5/5dAQEBys7O1uTJkzV9+nRNmDBBR48e1Zw5czRixAj95Cc/uabjTJs2TdOnT9fJkyc1aNAgff/73/fKOUtSfn6+68pabW2tjh07prfeekuSlJSU5PESI+DXfP0OaQDu6j6NVVBQcMV9U6ZMsdq0aVPvY6dOnbIef/xxKyoqygoMDLS6detmpaWlWefPn3fbp///6aFly5ZZN910k9W6dWurZ8+e1uuvv+5xzAMHDlhjxoyxwsPDraCgIKtv377WqlWr3PbUfRrrzTffrHeunJwcKzY21goICLAkuZ7/3U9jWdalT1TNnTvX6tatm9W6dWsrKirK+vnPf26Vlpa67evWrZt1zz33eHytpKQkKykpyXV/3rx5VkJCgtW+fXvLbrdbPXr0sJ566inr66+/rnfW6z13y7r2T2PVWb9+vdWnTx8rKCjIcjqd1syZM62Kioprfn5ZWZkVEhJiSbJWrlzp8XhjzjkpKcmSVO+tvk/UAf7MZlnfeWEfwA3DZrNpxowZys3N9fUoANBkeM8OAAAwGrEDAACMxhuUgRsYr2IDuBFwZQcAABiN2AEAAEYjdgAAgNF4z46kixcv6uTJkwoLC2v0j7kHAADNw7IsVVRUKDo6Wq1aXf76DbGjS7/j5ru/0RgAALQMJ06ccP16m/oQO5LCwsIkXfrL+u5vkAYAAP6pvLxcMTExru/jl0Ps6P9+Q3O7du2IHQAAWpirvQWFNygDAACjETsAAMBoxA4AADAasQMAAIxG7AAAAKMROwAAwGjEDgAAMBqxAwAAjEbsAAAAoxE7AADAaD6Nnffff19jxoxRdHS0bDabNm/e7Pa4ZVlKT09XdHS0QkJCNHToUB06dMhtT1VVlZ588kl17NhRbdq00b333qt//etfzXgWAADAn/k0ds6ePau+ffsqNze33sezs7O1ZMkS5ebmqqCgQE6nUyNGjFBFRYVrT2pqqjZt2qQNGzboww8/1JkzZzR69GjV1tY212kAAAA/ZrMsy/L1ENKlX+K1adMmjR07VtKlqzrR0dFKTU3V3LlzJV26iuNwOLR48WJNnz5dZWVlioyM1Nq1a/Xggw9Kkk6ePKmYmBj9+c9/1siRI6/pa5eXlys8PFxlZWX8IlAAAFqIa/3+7bfv2SksLFRxcbGSk5Nda3a7XUlJSdq5c6ckac+ePbpw4YLbnujoaMXHx7v2AACAG1ugrwe4nOLiYkmSw+FwW3c4HDp27JhrT1BQkNq3b++xp+759amqqlJVVZXrfnl5ubfGBgAAfsZvY6eOzWZzu29Zlsfad11tT1ZWljIyMrwy3/UY8PRrzf41AX+354WHfT2CVxxf1NvXIwB+p+szB3w9giQ/fhnL6XRKkscVmpKSEtfVHqfTqerqapWWll52T33S0tJUVlbmup04ccLL0wMAAH/ht7ETGxsrp9OpvLw811p1dbXy8/M1aNAgSdKAAQPUunVrtz1FRUU6ePCga0997Ha72rVr53YDAABm8unLWGfOnNEXX3zhul9YWKh9+/YpIiJCXbt2VWpqqjIzMxUXF6e4uDhlZmYqNDRUEydOlCSFh4fr0Ucf1ezZs9WhQwdFRETol7/8pXr37q277rrLV6cFAAD8iE9j5+OPP9awYcNc92fNmiVJmjJlilavXq05c+aosrJSKSkpKi0tVWJiorZt26awsDDXc1566SUFBgbqgQceUGVlpYYPH67Vq1crICCg2c8HAAD4H7/5OTu+1Fw/Z4c3KAOeeIMyYK6mfoNyi/85OwAAAN5A7AAAAKMROwAAwGjEDgAAMBqxAwAAjEbsAAAAoxE7AADAaMQOAAAwGrEDAACMRuwAAACjETsAAMBoxA4AADAasQMAAIxG7AAAAKMROwAAwGjEDgAAMBqxAwAAjEbsAAAAoxE7AADAaMQOAAAwGrEDAACMRuwAAACjETsAAMBoxA4AADAasQMAAIxG7AAAAKMROwAAwGjEDgAAMBqxAwAAjEbsAAAAoxE7AADAaMQOAAAwGrEDAACMRuwAAACjETsAAMBoxA4AADAasQMAAIxG7AAAAKMROwAAwGjEDgAAMBqxAwAAjEbsAAAAoxE7AADAaMQOAAAwGrEDAACMRuwAAACjETsAAMBoxA4AADAasQMAAIxG7AAAAKMROwAAwGjEDgAAMBqxAwAAjEbsAAAAoxE7AADAaMQOAAAwGrEDAACMRuwAAACjETsAAMBoxA4AADCaX8dOTU2NfvWrXyk2NlYhISHq0aOHFi1apIsXL7r2WJal9PR0RUdHKyQkREOHDtWhQ4d8ODUAAPAnfh07ixcv1iuvvKLc3Fx99tlnys7O1gsvvKCXX37ZtSc7O1tLlixRbm6uCgoK5HQ6NWLECFVUVPhwcgAA4C/8OnZ27dql++67T/fcc4+6d++u+++/X8nJyfr4448lXbqqk5OTo/nz52vcuHGKj4/XmjVrdO7cOa1fv97H0wMAAH/g17Hz4x//WNu3b9fnn38uSfrkk0/04Ycf6u6775YkFRYWqri4WMnJya7n2O12JSUlaefOnZc9blVVlcrLy91uAADATIG+HuBK5s6dq7KyMvXs2VMBAQGqra3Vc889pwkTJkiSiouLJUkOh8PteQ6HQ8eOHbvscbOyspSRkdF0gwMAAL/h11d2Nm7cqHXr1mn9+vX629/+pjVr1ujFF1/UmjVr3PbZbDa3+5Zleax9W1pamsrKyly3EydONMn8AADA9/z6ys7TTz+tefPm6aGHHpIk9e7dW8eOHVNWVpamTJkip9Mp6dIVnqioKNfzSkpKPK72fJvdbpfdbm/a4QEAgF/w6ys7586dU6tW7iMGBAS4PnoeGxsrp9OpvLw81+PV1dXKz8/XoEGDmnVWAADgn/z6ys6YMWP03HPPqWvXrvrBD36gvXv3asmSJZo2bZqkSy9fpaamKjMzU3FxcYqLi1NmZqZCQ0M1ceJEH08PAAD8gV/Hzssvv6wFCxYoJSVFJSUlio6O1vTp0/XMM8+49syZM0eVlZVKSUlRaWmpEhMTtW3bNoWFhflwcgAA4C9slmVZvh7C18rLyxUeHq6ysjK1a9euyb7OgKdfa7JjAy3Vnhce9vUIXnF8UW9fjwD4na7PHGjS41/r92+/fs8OAABAYxE7AADAaMQOAAAwGrEDAACMRuwAAACjETsAAMBoxA4AADAasQMAAIxG7AAAAKMROwAAwGjEDgAAMBqxAwAAjEbsAAAAoxE7AADAaMQOAAAwGrEDAACMRuwAAACjETsAAMBoxA4AADAasQMAAIxG7AAAAKMROwAAwGjEDgAAMBqxAwAAjEbsAAAAoxE7AADAaMQOAAAwGrEDAACMRuwAAACjETsAAMBoxA4AADAasQMAAIxG7AAAAKMROwAAwGjEDgAAMBqxAwAAjEbsAAAAoxE7AADAaMQOAAAwGrEDAACMRuwAAACjETsAAMBoxA4AADAasQMAAIxG7AAAAKMROwAAwGjEDgAAMBqxAwAAjEbsAAAAoxE7AADAaMQOAAAwGrEDAACMRuwAAACjETsAAMBoxA4AADAasQMAAIxG7AAAAKMROwAAwGjEDgAAMJrfx86///1v/ed//qc6dOig0NBQ9evXT3v27HE9blmW0tPTFR0drZCQEA0dOlSHDh3y4cQAAMCf+HXslJaW6o477lDr1q21detWffrpp/rNb36j733ve6492dnZWrJkiXJzc1VQUCCn06kRI0aooqLCd4MDAAC/EejrAa5k8eLFiomJ0apVq1xr3bt3d/3Zsizl5ORo/vz5GjdunCRpzZo1cjgcWr9+vaZPn97cIwMAAD/j11d2tmzZooSEBI0fP16dOnVS//79tXLlStfjhYWFKi4uVnJysmvNbrcrKSlJO3fu9MXIAADAz/h17PzjH//Q8uXLFRcXp7/85S96/PHHNXPmTL322muSpOLiYkmSw+Fwe57D4XA9Vp+qqiqVl5e73QAAgJn8+mWsixcvKiEhQZmZmZKk/v3769ChQ1q+fLkefvhh1z6bzeb2PMuyPNa+LSsrSxkZGU0zNAAA8Ct+fWUnKipKt956q9tar169dPz4cUmS0+mUJI+rOCUlJR5Xe74tLS1NZWVlrtuJEye8PDkAAPAXfh07d9xxh44cOeK29vnnn6tbt26SpNjYWDmdTuXl5bker66uVn5+vgYNGnTZ49rtdrVr187tBgAAzOTXL2M99dRTGjRokDIzM/XAAw/or3/9q1asWKEVK1ZIuvTyVWpqqjIzMxUXF6e4uDhlZmYqNDRUEydO9PH0AADAH/h17Nx+++3atGmT0tLStGjRIsXGxionJ0eTJk1y7ZkzZ44qKyuVkpKi0tJSJSYmatu2bQoLC/Ph5AAAwF/4dexI0ujRozV69OjLPm6z2ZSenq709PTmGwoAALQYfv2eHQAAgMYidgAAgNGIHQAAYLQGxc6dd96p06dPe6yXl5frzjvvbOxMAAAAXtOg2NmxY4eqq6s91s+fP68PPvig0UMBAAB4y3V9Gmv//v2uP3/66aduP7m4trZW77zzjjp37uy96QAAABrpumKnX79+stlsstls9b5cFRISopdfftlrwwEAADTWdcVOYWGhLMtSjx499Ne//lWRkZGux4KCgtSpUycFBAR4fUgAAICGuq7YqfudVBcvXmySYQAAALytwT9B+fPPP9eOHTtUUlLiET/PPPNMowcDAADwhgbFzsqVK/Xzn/9cHTt2lNPplM1mcz1ms9mIHQAA4DcaFDu//vWv9dxzz2nu3LnengcAAMCrGvRzdkpLSzV+/HhvzwIAAOB1DYqd8ePHa9u2bd6eBQAAwOsa9DLWzTffrAULFmj37t3q3bu3Wrdu7fb4zJkzvTIcAABAYzUodlasWKG2bdsqPz9f+fn5bo/ZbDZiBwAA+I0GxU5hYaG35wAAAGgSDXrPDgAAQEvRoCs706ZNu+Ljr776aoOGAQAA8LYGxU5paanb/QsXLujgwYM6ffp0vb8gFAAAwFcaFDubNm3yWLt48aJSUlLUo0ePRg8FAADgLV57z06rVq301FNP6aWXXvLWIQEAABrNq29Q/vvf/66amhpvHhIAAKBRGvQy1qxZs9zuW5aloqIivf3225oyZYpXBgMAAPCGBsXO3r173e63atVKkZGR+s1vfnPVT2oBAAA0pwbFznvvveftOQAAAJpEg2KnzldffaUjR47IZrPplltuUWRkpLfmAgAA8IoGvUH57NmzmjZtmqKiojRkyBANHjxY0dHRevTRR3Xu3DlvzwgAANBgDYqdWbNmKT8/X//7v/+r06dP6/Tp0/rjH/+o/Px8zZ4929szAgAANFiDXsb6wx/+oLfeektDhw51rd19990KCQnRAw88oOXLl3trPgAAgEZp0JWdc+fOyeFweKx36tSJl7EAAIBfaVDsDBw4UAsXLtT58+dda5WVlcrIyNDAgQO9NhwAAEBjNehlrJycHI0aNUpdunRR3759ZbPZtG/fPtntdm3bts3bMwIAADRYg2Knd+/eOnr0qNatW6fDhw/Lsiw99NBDmjRpkkJCQrw9IwAAQIM1KHaysrLkcDj02GOPua2/+uqr+uqrrzR37lyvDAcAANBYDXrPzu9+9zv17NnTY/0HP/iBXnnllUYPBQAA4C0Nip3i4mJFRUV5rEdGRqqoqKjRQwEAAHhLg2InJiZGH330kcf6Rx99pOjo6EYPBQAA4C0Nes/Oz372M6WmpurChQu68847JUnbt2/XnDlz+AnKAADArzQodubMmaNvvvlGKSkpqq6uliQFBwdr7ty5SktL8+qAAAAAjdGg2LHZbFq8eLEWLFigzz77TCEhIYqLi5Pdbvf2fAAAAI3SoNip07ZtW91+++3emgUAAMDrGvQGZQAAgJaC2AEAAEYjdgAAgNGIHQAAYDRiBwAAGI3YAQAARiN2AACA0YgdAABgNGIHAAAYjdgBAABGI3YAAIDRiB0AAGA0YgcAABiN2AEAAEYjdgAAgNGIHQAAYDRiBwAAGI3YAQAARmtRsZOVlSWbzabU1FTXmmVZSk9PV3R0tEJCQjR06FAdOnTId0MCAAC/0mJip6CgQCtWrFCfPn3c1rOzs7VkyRLl5uaqoKBATqdTI0aMUEVFhY8mBQAA/qRFxM6ZM2c0adIkrVy5Uu3bt3etW5alnJwczZ8/X+PGjVN8fLzWrFmjc+fOaf369T6cGAAA+IsWETszZszQPffco7vuusttvbCwUMXFxUpOTnat2e12JSUlaefOnZc9XlVVlcrLy91uAADATIG+HuBqNmzYoL/97W8qKCjweKy4uFiS5HA43NYdDoeOHTt22WNmZWUpIyPDu4MCAAC/5NdXdk6cOKFf/OIXWrdunYKDgy+7z2azud23LMtj7dvS0tJUVlbmup04ccJrMwMAAP/i11d29uzZo5KSEg0YMMC1Vltbq/fff1+5ubk6cuSIpEtXeKKiolx7SkpKPK72fJvdbpfdbm+6wQEAgN/w6ys7w4cP14EDB7Rv3z7XLSEhQZMmTdK+ffvUo0cPOZ1O5eXluZ5TXV2t/Px8DRo0yIeTAwAAf+HXV3bCwsIUHx/vttamTRt16NDBtZ6amqrMzEzFxcUpLi5OmZmZCg0N1cSJE30xMgAA8DN+HTvXYs6cOaqsrFRKSopKS0uVmJiobdu2KSwszNejAQAAP9DiYmfHjh1u9202m9LT05Wenu6TeQAAgH/z6/fsAAAANBaxAwAAjEbsAAAAoxE7AADAaMQOAAAwGrEDAACMRuwAAACjETsAAMBoxA4AADAasQMAAIxG7AAAAKMROwAAwGjEDgAAMBqxAwAAjEbsAAAAoxE7AADAaMQOAAAwGrEDAACMRuwAAACjETsAAMBoxA4AADAasQMAAIxG7AAAAKMROwAAwGjEDgAAMBqxAwAAjEbsAAAAoxE7AADAaMQOAAAwGrEDAACMRuwAAACjETsAAMBoxA4AADAasQMAAIxG7AAAAKMROwAAwGjEDgAAMBqxAwAAjEbsAAAAoxE7AADAaMQOAAAwGrEDAACMRuwAAACjETsAAMBoxA4AADAasQMAAIxG7AAAAKMROwAAwGjEDgAAMBqxAwAAjEbsAAAAoxE7AADAaMQOAAAwGrEDAACMRuwAAACjETsAAMBoxA4AADAasQMAAIxG7AAAAKP5dexkZWXp9ttvV1hYmDp16qSxY8fqyJEjbnssy1J6erqio6MVEhKioUOH6tChQz6aGAAA+Bu/jp38/HzNmDFDu3fvVl5enmpqapScnKyzZ8+69mRnZ2vJkiXKzc1VQUGBnE6nRowYoYqKCh9ODgAA/EWgrwe4knfeecft/qpVq9SpUyft2bNHQ4YMkWVZysnJ0fz58zVu3DhJ0po1a+RwOLR+/XpNnz7dF2MDAAA/4tdXdr6rrKxMkhQRESFJKiwsVHFxsZKTk1177Ha7kpKStHPnzssep6qqSuXl5W43AABgphYTO5ZladasWfrxj3+s+Ph4SVJxcbEkyeFwuO11OByux+qTlZWl8PBw1y0mJqbpBgcAAD7VYmLniSee0P79+/XGG294PGaz2dzuW5blsfZtaWlpKisrc91OnDjh9XkBAIB/8Ov37NR58skntWXLFr3//vvq0qWLa93pdEq6dIUnKirKtV5SUuJxtefb7Ha77HZ70w0MAAD8hl9f2bEsS0888YT+53/+R++++65iY2PdHo+NjZXT6VReXp5rrbq6Wvn5+Ro0aFBzjwsAAPyQX1/ZmTFjhtavX68//vGPCgsLc70PJzw8XCEhIbLZbEpNTVVmZqbi4uIUFxenzMxMhYaGauLEiT6eHgAA+AO/jp3ly5dLkoYOHeq2vmrVKk2dOlWSNGfOHFVWViolJUWlpaVKTEzUtm3bFBYW1szTAgAAf+TXsWNZ1lX32Gw2paenKz09vekHAgAALY5fv2cHAACgsYgdAABgNGIHAAAYjdgBAABGI3YAAIDRiB0AAGA0YgcAABiN2AEAAEYjdgAAgNGIHQAAYDRiBwAAGI3YAQAARiN2AACA0YgdAABgNGIHAAAYjdgBAABGI3YAAIDRiB0AAGA0YgcAABiN2AEAAEYjdgAAgNGIHQAAYDRiBwAAGI3YAQAARiN2AACA0YgdAABgNGIHAAAYjdgBAABGI3YAAIDRiB0AAGA0YgcAABiN2AEAAEYjdgAAgNGIHQAAYDRiBwAAGI3YAQAARiN2AACA0YgdAABgNGIHAAAYjdgBAABGI3YAAIDRiB0AAGA0YgcAABiN2AEAAEYjdgAAgNGIHQAAYDRiBwAAGI3YAQAARiN2AACA0YgdAABgNGIHAAAYjdgBAABGI3YAAIDRiB0AAGA0YgcAABiN2AEAAEYjdgAAgNGIHQAAYDRiBwAAGM2Y2Fm2bJliY2MVHBysAQMG6IMPPvD1SAAAwA8YETsbN25Uamqq5s+fr71792rw4MEaNWqUjh8/7uvRAACAjxkRO0uWLNGjjz6qn/3sZ+rVq5dycnIUExOj5cuX+3o0AADgYy0+dqqrq7Vnzx4lJye7rScnJ2vnzp0+mgoAAPiLQF8P0Fhff/21amtr5XA43NYdDoeKi4vrfU5VVZWqqqpc98vKyiRJ5eXlTTeopNqqyiY9PtASNfW/u+ZScb7W1yMAfqep/33XHd+yrCvua/GxU8dms7ndtyzLY61OVlaWMjIyPNZjYmKaZDYAlxf+8uO+HgFAU8kKb5YvU1FRofDwy3+tFh87HTt2VEBAgMdVnJKSEo+rPXXS0tI0a9Ys1/2LFy/qm2++UYcOHS4bSDBHeXm5YmJidOLECbVr187X4wDwIv5931gsy1JFRYWio6OvuK/Fx05QUJAGDBigvLw8/cd//IdrPS8vT/fdd1+9z7Hb7bLb7W5r3/ve95pyTPihdu3a8T+GgKH4933juNIVnTotPnYkadasWZo8ebISEhI0cOBArVixQsePH9fjj3N5HACAG50RsfPggw/q1KlTWrRokYqKihQfH68///nP6tatm69HAwAAPmZE7EhSSkqKUlJSfD0GWgC73a6FCxd6vJQJoOXj3zfqY7Ou9nktAACAFqzF/1BBAACAKyF2AACA0YgdAABgNGIHAAAYjdjBDWXZsmWKjY1VcHCwBgwYoA8++MDXIwHwgvfff19jxoxRdHS0bDabNm/e7OuR4EeIHdwwNm7cqNTUVM2fP1979+7V4MGDNWrUKB0/ftzXowFopLNnz6pv377Kzc319SjwQ3z0HDeMxMRE3XbbbVq+fLlrrVevXho7dqyysrJ8OBkAb7LZbNq0aZPGjh3r61HgJ7iygxtCdXW19uzZo+TkZLf15ORk7dy500dTAQCaA7GDG8LXX3+t2tpaORwOt3WHw6Hi4mIfTQUAaA7EDm4oNpvN7b5lWR5rAACzEDu4IXTs2FEBAQEeV3FKSko8rvYAAMxC7OCGEBQUpAEDBigvL89tPS8vT4MGDfLRVACA5mDMbz0HrmbWrFmaPHmyEhISNHDgQK1YsULHjx/X448/7uvRADTSmTNn9MUXX7juFxYWat++fYqIiFDXrl19OBn8AR89xw1l2bJlys7OVlFRkeLj4/XSSy9pyJAhvh4LQCPt2LFDw4YN81ifMmWKVq9e3fwDwa8QOwAAwGi8ZwcAABiN2AEAAEYjdgAAgNGIHQAAYDRiBwAAGI3YAQAARiN2AACA0YgdAH5v6NChSk1Nvaa9O3bskM1m0+nTpxv1Nbt3766cnJxGHQOAfyB2AACA0YgdAABgNGIHQIuybt06JSQkKCwsTE6nUxMnTlRJSYnHvo8++kh9+/ZVcHCwEhMTdeDAAbfHd+7cqSFDhigkJEQxMTGaOXOmzp4921ynAaAZETsAWpTq6mo9++yz+uSTT7R582YVFhZq6tSpHvuefvppvfjiiyooKFCnTp1077336sKFC5KkAwcOaOTIkRo3bpz279+vjRs36sMPP9QTTzzRzGcDoDkE+noAALge06ZNc/25R48eWrp0qX74wx/qzJkzatu2reuxhQsXasSIEZKkNWvWqEuXLtq0aZMeeOABvfDCC5o4caLrTc9xcXFaunSpkpKStHz5cgUHBzfrOQFoWlzZAdCi7N27V/fdd5+6deumsLAwDR06VJJ0/Phxt30DBw50/TkiIkLf//739dlnn0mS9uzZo9WrV6tt27au28iRI3Xx4kUVFhY227kAaB5c2QHQYpw9e1bJyclKTk7WunXrFBkZqePHj2vkyJGqrq6+6vNtNpsk6eLFi5o+fbpmzpzpsadr165enxuAbxE7AFqMw4cP6+uvv9bzzz+vmJgYSdLHH39c797du3e7wqW0tFSff/65evbsKUm67bbbdOjQId18883NMzgAn+JlLAAtRteuXRUUFKSXX35Z//jHP7RlyxY9++yz9e5dtGiRtm/froMHD2rq1Knq2LGjxo4dK0maO3eudu3apRkzZmjfvn06evSotmzZoieffLIZzwZAcyF2ALQYkZGRWr16td58803deuutev755/Xiiy/Wu/f555/XL37xCw0YMEBFRUXasmWLgoKCJEl9+vRRfn6+jh49qsGDB6t///5asGCBoqKimvN0ADQTm2VZlq+HAAAAaCpc2QEAAEYjdgAAgNGIHQAAYDRiBwAAGI3YAQAARiN2AACA0YgdAABgNGIHAAAYjdgBAABGI3YAAIDRiB0AAGA0YgcAABjt/wFcUACS6CI4jAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Data.Target_proportions(Data.val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7fee057c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['t3', '60', 'rd', 'do', 'b1', 'dp', 'to', 'cr', 'ib', 'pa', 'vg',\n",
       "        'bp', '64', 'pr', 'dl', 'bi', 'mi', 'nk', '06', '27', 'hi', '36',\n",
       "        'gu', '25', 're', 'id', '15', '23', '3x', '4d', '44', 'od', 'hg',\n",
       "        'l2', '53', '50', '93', '37', 'ps', 'my', '2b', 'md', '3a', 'of',\n",
       "        '07', 'pk', '49', '84', 'ms', 'tv', 'gp', '01', '22', 'pn', '83',\n",
       "        'a1', '39', '85', 't0', '26', 'n3', '2d', 'hz', 'g5', '19', 'a3',\n",
       "        '57', 'sd', 'fl', 'ic', 'cd', 'm3', 'ua', 'za', 'pc', 'ki', '35',\n",
       "        '16', 'uk', 'pp', 'he', 'os', '14', 'hb', '1p', 'mk', '66', 'pt',\n",
       "        'v3', 'xi', '86', 'el', '96', 'iv', '13', 'fu', '73', 'kg', '47',\n",
       "        '76', '91', 'mm', '87', 'bl', '82', '67', 'de', 'qt', '46', 'vi',\n",
       "        'd2', 'wp', 'l1', 'et', 'er', 'll', 'da', 'hf', 'cm', '38', '48',\n",
       "        '88', '72', 'tc', '7x', '40', 'sb', 't1', '97', 'rh', '3c', 'ct',\n",
       "        'up', '42', 'so', '2x', '12', 'gi', 'as', '00', '11', '1c', 'ie',\n",
       "        '65', '08', '54', '68', 'at', '32', '80', 'e2', 'lv', '70', 'b2',\n",
       "        'pi', 'ph', 'oh', 'wk', 'ef', 'ac', '62', 'pd', 'tn', 'p6', '03',\n",
       "        '24', 'mf', '98', 'dx', 'ab', 'yr', '7h', '71', '69', 'pm', 'il',\n",
       "        '81', '77', 'an', 'ls', 'bd', 't4', '31', 'fb', '29', '59', '43',\n",
       "        'v1', 'tp', 'gy', 'av', 'ah', '28', 'vs', 'gr', 'tr', 'a2', '52',\n",
       "        've', 'ok', '0g', 'mx', 'gm', 'ks', '79', 'm2', '55', 'ul', '04',\n",
       "        '75', 'n2', '30', '95', '90', 'qw', '45', 'm1', 'it', '92', 'l4',\n",
       "        'ai', '61', 'ma', 'n1', 'in', 'na', 'ad', '05', 'eg', '78', 'bm',\n",
       "        '5x', 'sm', 'ge', 'ut', 'tb', 'al', '89', 'qd', 'ca', '09', 'go',\n",
       "        'by', 'v4', 'um', 'n0', 'pg', 'ml', '63', 'tl', 'ec', 'ln', 'no',\n",
       "        'ng', 'h1', '18', 'uc', 'sn', 'oa', '3d', '21', '20', 'ld', 'if',\n",
       "        'o2', 'g2', 'ta', 'cc', 'lr', 'ag', '3b', '99', '94', 'be', 'ds',\n",
       "        '1b', 'lh', 'm0', 'ii', 'h2', '17', 'is', 'sc', 'co', '6x', 'rs',\n",
       "        'po', 'ar', 'ae', 'li', 'ap', '51', 'dc', 'bt', 'iu', '5c', '34',\n",
       "        't2', 'mr', '1g', 'la', 'p1', '10', 'fc', 'or', '56', 'we', 'am',\n",
       "        'ts', 'ci', 'ex', '41', 'rt', '1t', 'cb', '33', 'ia', 'mg', 'hr',\n",
       "        'tx', '58', 'on', '74', 'st', '02'], dtype='<U2'),\n",
       " 1785)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([key for key in list(Data.word2index.keys()) if len(key)==2]), Data.word2index['zero']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f4cb3c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemEval_Dataset(Dataset):\n",
    "    def __init__(self, Statment, Trial1, Trial2, Labels, word2index, max_len=[66, 1583, 1405]):\n",
    "        \n",
    "        self.Statment = Statment\n",
    "        self.Trial1 = Trial1\n",
    "        self.Trial2 = Trial2\n",
    "\n",
    "        self.labels = Labels\n",
    "        \n",
    "        self.max_len = max_len\n",
    "        self.word2index = word2index\n",
    "        \n",
    "    def Encode_Pad_seq(self, text, max_len_id):\n",
    "        Encoded_text = [0]*self.max_len[max_len_id]\n",
    "        for i, word in enumerate(text.split()):\n",
    "            if word in self.word2index.keys():\n",
    "                Encoded_text[i] = self.word2index[word]\n",
    "            else:\n",
    "                Encoded_text[i] = self.word2index['UNK']\n",
    "            if i == self.max_len:\n",
    "                break\n",
    "        return Encoded_text, len(text.split())\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        S1, S2, S3, label = self.Statment[idx], self.Trial1[idx], self.Trial2[idx], self.labels[idx]\n",
    "        \n",
    "        x1, len1 = self.Encode_Pad_seq(S1, 0)\n",
    "        x2, len2 = self.Encode_Pad_seq(S2, 1)\n",
    "        x3, len3 = self.Encode_Pad_seq(S3, 2)\n",
    "\n",
    "        return torch.LongTensor(np.array(x1)), torch.tensor(len1), torch.LongTensor(np.array(x2)), torch.tensor(len2), torch.LongTensor(np.array(x3)), torch.tensor(len3), torch.tensor(label)\n",
    "\n",
    "train_dataset = SemEval_Dataset(Data.train_df['statement'].tolist(), Data.train_df['trail1'].tolist(), Data.train_df['trail2'].tolist(), Data.train_df['label'].tolist(), Data.word2index)\n",
    "val_dataset = SemEval_Dataset(Data.val_df['statement'].tolist(), Data.val_df['trail1'].tolist(), Data.train_df['trail2'].tolist(), Data.val_df['label'].tolist(), Data.word2index)\n",
    "test_dataset = SemEval_Dataset(Data.test_df['statement'].tolist(), Data.test_df['trail1'].tolist(), Data.train_df['trail2'].tolist(), Data.test_df['label'].tolist(), Data.word2index)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5c15b4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4688, 7138,  216, 3418, 1363,   98, 2744, 1948, 4611, 6738, 3296, 6738,\n",
       "         3882, 1100, 6707, 1493, 2048, 4794, 6262, 4688, 7138, 4279, 3418, 2083,\n",
       "         1948,  341,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0]),\n",
       " tensor(26),\n",
       " tensor([1137, 6375, 4791,  ...,    0,    0,    0]),\n",
       " tensor(79),\n",
       " tensor([1137, 6375, 6425,  ...,    0,    0,    0]),\n",
       " tensor(100),\n",
       " tensor(0))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "c3761596",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNLI_BiLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        \n",
    "        super().__init__()\n",
    "                                \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = 0)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        self.translation = nn.Linear(embedding_dim, hidden_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, bidirectional=True, dropout=0.2, batch_first=True)\n",
    "#         self.attention = Attention(hidden_dim)\n",
    "\n",
    "#         self.fc1 = nn.Linear(hidden_dim * 2, 512) # CrossProduct(S1,S2)\n",
    "        self.fc1 = nn.Linear(hidden_dim * 2 * 3, 512) # Concatenation of S1 and S2\n",
    "#         self.fc1 = nn.Linear((hidden_dim * 2 * 2)+256, 512) # Concatenation of S1, S2, CrossProduct(S1,S2)\n",
    "\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        \n",
    "        self.fc_out = nn.Linear(128, 2)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, stat, l1, trial1, l2, trial2, l3):      \n",
    "        embedded_stat = self.embedding(stat)\n",
    "        embedded_stat = self.dropout(embedded_stat)\n",
    "        embedded_stat = F.relu(self.translation(embedded_stat))\n",
    "        outputs_stat, (hidden_stat, cell_stat) = self.lstm(embedded_stat)\n",
    "\n",
    "        embedded_trial1 = self.embedding(trial1)\n",
    "        embedded_trial1 = self.dropout(embedded_trial1)\n",
    "        embedded_trial1 = F.relu(self.translation(embedded_trial1))\n",
    "        outputs_trial1, (hidden_trial1, cell_trial1) = self.lstm(embedded_trial1)\n",
    "        \n",
    "        embedded_trial2 = self.embedding(trial2)\n",
    "        embedded_trial2 = self.dropout(embedded_trial2)\n",
    "        embedded_trial2 = F.relu(self.translation(embedded_trial2))\n",
    "        outputs_trial2, (hidden_trial2, cell_trial2) = self.lstm(embedded_trial2)\n",
    "        \n",
    "        hidden_stat = torch.cat((hidden_stat[-1], hidden_stat[-2]), dim=-1)\n",
    "        hidden_trial1 = torch.cat((hidden_trial1[-1], hidden_trial1[-2]), dim=-1)\n",
    "        hidden_trial2 = torch.cat((hidden_trial2[-1], hidden_trial2[-2]), dim=-1)\n",
    "\n",
    "        out = torch.cat((hidden_stat, hidden_trial1, hidden_trial1), dim=-1) # \n",
    "#         out = hidden_prem * hidden_hypo # Cross product\n",
    "#         out = torch.cat((hidden_prem, hidden_hypo, out), dim=-1)\n",
    "    \n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.dropout(out)\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.dropout(out)\n",
    "        out = F.relu(self.fc3(out))\n",
    "        out = self.dropout(out)\n",
    "        prediction = self.fc_out(out)\n",
    "                \n",
    "        return prediction\n",
    "    \n",
    "class SNLI_BiLSTM_var_Len(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        \n",
    "        super().__init__()\n",
    "                                \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = 0)\n",
    "        self.translation = nn.Linear(embedding_dim, hidden_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, dropout=0.2, batch_first=True)\n",
    "#         self.fc1 = nn.Linear(hidden_dim * 2, 512) # CrossProduct(S1,S2)\n",
    "        self.fc1 = nn.Linear(hidden_dim * 2 * 3, 512) # Concatenation of S1 and S2\n",
    "#         self.fc1 = nn.Linear((hidden_dim * 2 * 2)+256, 512) # Concatenation of S1, S2, CrossProduct(S1,S2)\n",
    "\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        \n",
    "        self.fc_out = nn.Linear(128, 2)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, stat, l1, trial1, l2, trial2, l3):\n",
    "        embedded_stat = self.embedding(stat)\n",
    "        embedded_stat = nn.utils.rnn.pack_padded_sequence(embedded_stat, l1.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        outputs_stat, (hidden_stat, cell_stat) = self.lstm(embedded_stat)\n",
    "\n",
    "        embedded_trial1 = self.embedding(trial1)\n",
    "        embedded_trial1 = nn.utils.rnn.pack_padded_sequence(embedded_trial1, l2.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        outputs_trial1, (hidden_trial1, cell_trial1) = self.lstm(embedded_trial1)\n",
    "        \n",
    "        embedded_trial2 = self.embedding(trial2)\n",
    "        embedded_trial2 = nn.utils.rnn.pack_padded_sequence(embedded_trial2, l3.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        outputs_trial2, (hidden_trial2, cell_trial2) = self.lstm(embedded_trial2)\n",
    "\n",
    "        hidden_stat = torch.cat((hidden_stat[-1], hidden_stat[-2]), dim=-1)\n",
    "        hidden_trial1 = torch.cat((hidden_trial1[-1], hidden_trial1[-2]), dim=-1)\n",
    "        hidden_trial2 = torch.cat((hidden_trial2[-1], hidden_trial2[-2]), dim=-1)\n",
    "\n",
    "        \n",
    "        out = torch.cat((hidden_stat, hidden_trial1, hidden_trial1), dim=-1) # \n",
    "#         out = hidden_prem * hidden_hypo # Cross product\n",
    "#         out = torch.cat((hidden_prem, hidden_hypo, out), dim=-1)\n",
    "    \n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.dropout(out)\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.dropout(out)\n",
    "        out = F.relu(self.fc3(out))\n",
    "        out = self.dropout(out)\n",
    "        prediction = self.fc_out(out)\n",
    "                \n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5158e81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Text_Entailment(pl.LightningModule):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
    "        super(Text_Entailment, self).__init__()\n",
    "#         self.model = SNLI_BiLSTM(vocab_size, embedding_dim, hidden_dim)\n",
    "        self.model = SNLI_BiLSTM_var_Len(vocab_size, embedding_dim, hidden_dim)\n",
    "        self.CE = nn.CrossEntropyLoss()\n",
    "        self.Faithfulness = nn.L1Loss()\n",
    "\n",
    "    def forward(self, x1, l1, x2, l2, x3, l3):\n",
    "        return self.model(x1, l1, x2, l2, x3, l3)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x1, l1, x2, l2, x3, l3, y = batch\n",
    "        y_hat = self.forward(x1, l1, x2, l2, x3, l3)\n",
    "        \n",
    "        probs = F.softmax(y_hat, dim=1)\n",
    "        _, predicted_classes = torch.max(probs, dim=1)\n",
    "            \n",
    "        loss = self.CE(y_hat, y)\n",
    "        self.log('Train_loss', loss, prog_bar=True, logger=True)\n",
    "        \n",
    "        acc = self.Faithfulness(predicted_classes.float(), y.float())\n",
    "        self.log('Train_acc', acc, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x1, l1, x2, l2, x3, l3, y = batch\n",
    "        y_hat = self.forward(x1, l1, x2, l2, x3, l3)\n",
    "        \n",
    "        loss = self.CE(y_hat, y)\n",
    "        self.log('Val_loss', loss, prog_bar=True, logger=True)\n",
    "        \n",
    "        probs = F.softmax(y_hat, dim=1)\n",
    "        _, predicted_classes = torch.max(probs, dim=1)\n",
    "        \n",
    "        acc = self.Faithfulness(predicted_classes.float(), y.float())\n",
    "        self.log('Val_acc', acc, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "        x1, l1, x2, l2, x3, l3, y = test_batch\n",
    "        y_hat = self.forward(x1, l1, x2, l2, x3, l3)\n",
    "        loss = self.CE(y_hat, y)\n",
    "        \n",
    "        probs = F.softmax(y_hat, dim=1)\n",
    "        _, predicted_classes = torch.max(probs, dim=1)\n",
    "\n",
    "        acc = self.Faithfulness(predicted_classes.float(), y.float())\n",
    "        \n",
    "        self.log('test_loss', loss)\n",
    "        self.log('test_acc', acc, prog_bar=True)\n",
    "\n",
    "        print('Test_acc', acc)\n",
    "    \n",
    "    def predict_step(self, test_batch, batch_idx, dataloader_idx=None):\n",
    "        with torch.no_grad():\n",
    "            x1, l1, x2, l2, x3, l3, y = test_batch  # Assuming your input data is the first element of the batch\n",
    "            logits = self.forward(x1, l1, x2, l2, x3, l3)  # Get logits from your model\n",
    "\n",
    "            # Apply softmax to get probability distribution over classes\n",
    "            probabilities = F.softmax(logits, dim=1)\n",
    "\n",
    "            # Get class predictions by finding the class with the highest probability\n",
    "            _, predicted_classes = torch.max(probabilities, dim=1)\n",
    "\n",
    "        return predicted_classes.tolist()\n",
    "    \n",
    "#     def Faithfulness(self, y_hat, y):\n",
    "#         assert y_hat.shape == y.shape\n",
    "#         abs_diff = np.abs(y_hat - y)/y.shape[0]\n",
    "#         return abs_diff\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "117dd7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text_Entailment(\n",
      "  (model): SNLI_BiLSTM_var_Len(\n",
      "    (embedding): Embedding(7220, 100, padding_idx=0)\n",
      "    (translation): Linear(in_features=100, out_features=128, bias=True)\n",
      "    (lstm): LSTM(100, 128, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "    (fc1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (fc_out): Linear(in_features=128, out_features=2, bias=True)\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (CE): CrossEntropyLoss()\n",
      "  (Faithfulness): L1Loss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(Data.word2index)\n",
    "embedding_dim = 100\n",
    "hidden_dim = 128\n",
    "\n",
    "Model = Text_Entailment(vocab_size, embedding_dim, hidden_dim).to(device)\n",
    "print(Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e08b7cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "3415it [00:00, 33979.66it/s]\u001b[A\n",
      "9188it [00:00, 47865.76it/s]\u001b[A\n",
      "18484it [00:00, 68233.03it/s]\u001b[A\n",
      "30690it [00:00, 89364.58it/s]\u001b[A\n",
      "40715it [00:00, 93271.83it/s]\u001b[A\n",
      "54024it [00:00, 106514.31it/s]\u001b[A\n",
      "69338it [00:00, 121580.80it/s]\u001b[A\n",
      "84937it [00:00, 132214.23it/s]\u001b[A\n",
      "98245it [00:00, 132197.66it/s]\u001b[A\n",
      "114136it [00:01, 140006.94it/s]\u001b[A\n",
      "128134it [00:01, 139203.60it/s]\u001b[A\n",
      "142053it [00:01, 137604.73it/s]\u001b[A\n",
      "156781it [00:01, 140067.47it/s]\u001b[A\n",
      "171156it [00:01, 140638.46it/s]\u001b[A\n",
      "185222it [00:01, 138167.04it/s]\u001b[A\n",
      "199048it [00:01, 135114.44it/s]\u001b[A\n",
      "212700it [00:01, 135114.12it/s]\u001b[A\n",
      "228683it [00:01, 142118.00it/s]\u001b[A\n",
      "242916it [00:01, 140853.29it/s]\u001b[A\n",
      "257855it [00:02, 142944.43it/s]\u001b[A\n",
      "272163it [00:02, 142579.59it/s]\u001b[A\n",
      "287768it [00:02, 146465.48it/s]\u001b[A\n",
      "304451it [00:02, 152192.27it/s]\u001b[A\n",
      "319681it [00:02, 148842.66it/s]\u001b[A\n",
      "335567it [00:02, 151372.51it/s]\u001b[A\n",
      "351098it [00:02, 152459.78it/s]\u001b[A\n",
      "366359it [00:02, 145138.27it/s]\u001b[A\n",
      "381503it [00:02, 146603.24it/s]\u001b[A\n",
      "400000it [00:02, 133674.68it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.54% of vocab had a pre-trained embedding!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_pretrained_glove_vectors(vocab, root='C:/Users/35846/Desktop/Deep Learning Projects/Glove'):\n",
    "    # url = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
    "    # download_and_extract(url, root)\n",
    "    \n",
    "    embedding_dim = 100\n",
    "    vectors = torch.zeros(len(vocab.keys()), embedding_dim)\n",
    "    found = 0\n",
    "    no_embed = []\n",
    "    with open(f'{root}/glove.6B.{embedding_dim}d.txt', 'r', encoding=\"utf8\") as f:\n",
    "        for line in tqdm(f):\n",
    "            token, *vector = line.split()\n",
    "            if token in vocab.keys():\n",
    "                found += 1\n",
    "                vector = [float(v) for v in vector]\n",
    "                vectors[vocab[token]] = torch.FloatTensor(vector)\n",
    "            else:\n",
    "                no_embed.append(token)\n",
    "    print(f'{found/len(vocab)*100:.2f}% of vocab had a pre-trained embedding!')\n",
    "    return vectors, no_embed\n",
    "\n",
    "pretrained_vectors, no_embed = get_pretrained_glove_vectors(Data.word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c695f509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393896"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "41e3754c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.8764,  0.2643, -0.3254,  ..., -0.6425,  0.2861,  0.6296],\n",
       "        ...,\n",
       "        [ 0.0725, -0.1586, -0.3730,  ..., -0.2002, -0.6224,  0.4096],\n",
       "        [-0.4527,  0.9526,  0.4424,  ...,  0.0189,  0.0202,  0.0712],\n",
       "        [-0.2291, -0.2357,  0.0532,  ..., -0.5439,  0.2925, -0.4862]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.model.embedding.weight.data.copy_(pretrained_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "8dda069a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type                | Params\n",
      "-----------------------------------------------------\n",
      "0 | model        | SNLI_BiLSTM_var_Len | 1.5 M \n",
      "1 | CE           | CrossEntropyLoss    | 0     \n",
      "2 | Faithfulness | L1Loss              | 0     \n",
      "-----------------------------------------------------\n",
      "1.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.5 M     Total params\n",
      "6.115     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee391f7612794c8b801b7156ef9b8076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Length of all samples has to be greater than 0, but found an element in 'lengths' that is <= 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[183], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:531\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    529\u001b[0m model \u001b[38;5;241m=\u001b[39m _maybe_unwrap_optimized(model)\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m--> 531\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:42\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     45\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:570\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_connector\u001b[38;5;241m.\u001b[39mattach_data(\n\u001b[0;32m    561\u001b[0m     model, train_dataloaders\u001b[38;5;241m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[38;5;241m=\u001b[39mval_dataloaders, datamodule\u001b[38;5;241m=\u001b[39mdatamodule\n\u001b[0;32m    562\u001b[0m )\n\u001b[0;32m    564\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    566\u001b[0m     ckpt_path,\n\u001b[0;32m    567\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    568\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    569\u001b[0m )\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:975\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    974\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 975\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    979\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    980\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1016\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[0;32m   1015\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[1;32m-> 1016\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m   1018\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1045\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1042\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[1;32m-> 1045\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1047\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\loops\\utilities.py:177\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[1;32m--> 177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loop_run(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py:115\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    113\u001b[0m     previous_dataloader_idx \u001b[38;5;241m=\u001b[39m dataloader_idx\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py:375\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[1;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_started()\n\u001b[0;32m    374\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 375\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_kwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[0;32m    379\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_test_batch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_validation_batch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:287\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[1;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 287\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m    290\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:379\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mval_step_context():\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, ValidationStep)\n\u001b[1;32m--> 379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mvalidation_step(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[180], line 29\u001b[0m, in \u001b[0;36mText_Entailment.validation_step\u001b[1;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidation_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, batch_idx):\n\u001b[0;32m     28\u001b[0m     x1, l1, x2, l2, x3, l3, y \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m---> 29\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCE(y_hat, y)\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVal_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, loss, prog_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, logger\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[180], line 10\u001b[0m, in \u001b[0;36mText_Entailment.forward\u001b[1;34m(self, x1, l1, x2, l2, x3, l3)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x1, l1, x2, l2, x3, l3):\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml3\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[179], line 87\u001b[0m, in \u001b[0;36mSNLI_BiLSTM_var_Len.forward\u001b[1;34m(self, stat, l1, trial1, l2, trial2, l3)\u001b[0m\n\u001b[0;32m     84\u001b[0m outputs_trial1, (hidden_trial1, cell_trial1) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(embedded_trial1)\n\u001b[0;32m     86\u001b[0m embedded_trial2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(trial2)\n\u001b[1;32m---> 87\u001b[0m embedded_trial2 \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpack_padded_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedded_trial2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menforce_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m outputs_trial2, (hidden_trial2, cell_trial2) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(embedded_trial2)\n\u001b[0;32m     90\u001b[0m hidden_stat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((hidden_stat[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], hidden_stat[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\utils\\rnn.py:263\u001b[0m, in \u001b[0;36mpack_padded_sequence\u001b[1;34m(input, lengths, batch_first, enforce_sorted)\u001b[0m\n\u001b[0;32m    259\u001b[0m     batch_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_first \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mindex_select(batch_dim, sorted_indices)\n\u001b[0;32m    262\u001b[0m data, batch_sizes \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m--> 263\u001b[0m     \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pack_padded_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _packed_sequence_init(data, batch_sizes, sorted_indices, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Length of all samples has to be greater than 0, but found an element in 'lengths' that is <= 0"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=32)\n",
    "trainer.fit(Model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "598e4f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63cc4bef8c044e33851384e71f3fcfc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_acc tensor(0.5050, device='cuda:0')\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.5049999952316284\n",
      "        test_loss           0.6983451843261719\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.6983451843261719, 'test_acc': 0.5049999952316284}]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(Model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c10d0cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8cbba249ff04c6da7a97e9060735ff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(Model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "2dcc6fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 2, 2, 1, 0, 2, 0, 2, 0, 2, 0, 0, 1, 1, 0, 2, 0, 1, 0, 1,\n",
       "       0, 2, 2, 1, 0, 0, 2, 1, 1, 2, 0, 0, 0, 1, 2, 1, 1, 0, 2, 1, 1, 2,\n",
       "       2, 1, 2, 0, 2, 1, 2, 0, 1, 2, 1, 0, 0, 1, 2, 0, 1, 0, 2, 0, 2, 0,\n",
       "       2, 1, 1, 2, 0, 1, 2, 2, 1, 0, 2, 0, 2, 0, 0, 1, 0, 0, 0, 0, 1, 2,\n",
       "       0, 2, 1, 0, 1, 1, 1, 1, 0, 1, 2, 0, 1, 2, 0, 1, 0, 0, 0, 1, 0, 2,\n",
       "       0, 2, 2, 0, 1, 2, 0, 1, 1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 1, 1, 2, 0,\n",
       "       2, 0, 1, 2, 1, 2, 0, 1, 1, 2, 0, 1, 2, 1, 0, 2, 2, 1, 0, 2, 1, 1,\n",
       "       1, 0, 2, 2, 0, 2, 2, 1, 1, 2, 1, 0, 0, 2, 1, 0, 0, 0, 1, 2, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 2, 2, 0, 1, 1, 2, 1, 0, 2, 1, 0, 2, 1, 0, 1, 2,\n",
       "       1, 1, 0, 2, 1, 2, 0, 0, 0, 2, 1, 0, 0, 0, 1, 0, 2, 0, 2, 1, 0, 1,\n",
       "       2, 2, 0, 1, 2, 0, 1, 1, 0, 2, 0, 2, 2, 2, 0, 1, 0, 1, 2, 1, 2, 0,\n",
       "       2, 0, 1, 1, 2, 1, 2, 1, 0, 1, 0, 2, 2, 1])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(predictions[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
